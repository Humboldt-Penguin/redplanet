{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RedPlanet","text":"<p>RedPlanet is an open-source Python library for working with various Mars geophysical datasets. We aim to streamline data analysis/visualization workflows for beginners and experts alike, so you spend less time hunting/wrangling data and more time doing cool science! :) (1)</p> <ol> <li>Fun story: I recently spent 6 hours on a Saturday trying to find/compute a high-resolution (greater than 1x1 degree) Bouguer anomaly dataset.  I have intermediate knowledge of search engine techniques, and I like to think I'm not completely incompetent (you can judge for yourself based on my work on this package/website) \u2014 but I was still tearing my hair out on what should have been a simple task.  Resources such as pyshtools (both the software and documentation website) and Zenodo are shining examples of how we can make our analysis workflows more accessible/reproducible and increase our scientific productivity. I hope RedPlanet can contribute to that ecosystem. </li> </ol> <p> </p>"},{"location":"#key-features","title":"Key Features","text":"<p>(citations are missing from here until I figure out how I'm handling that)</p> <ul> <li>Crater database which unifies [1] comprehensive database of craters D&gt;=1km, [2] crater ages from both Hartmann and Neukum isochron-fitting, and [3] official/up-to-date IAU crater names.</li> <li>Digital elevation models up to 200m resolution with memory-mapping, parallelization, and chunking for high-performance.</li> <li>Mohorovi\u010di\u0107 discontinuity (crust-mantle interface) models and derived crustal thickness maps \u2014 models are parameterized by north/south crustal density, reference interior models, and crustal thickness beneath the InSight lander with a total of ~20,000 valid combinations.</li> <li>Magnetic source depth data from spherical harmonic inversions.</li> <li>Heat flow and Curie depth calculations from gamma-ray spectroscopy (GRS) data.</li> <li>(Planned for future) MAVEN magnetometer data, filtered for nighttime and low-altitude.</li> </ul> <p> </p> <p>Here's a sample plot generated with RedPlanet:</p> <p></p> <p> </p>"},{"location":"#online-demo","title":"Online Demo","text":"<p>Whether you're a beginner who's never installed Python before or an advanced user who'd like a demo before installing, Google Colab is a great way to try all the features of RedPlanet completely in your browser without installing anything! Just open the link above.</p>"},{"location":"home/about/changelog/","title":"Changelog","text":""},{"location":"home/about/changelog/#1-planned-features","title":"[1] Planned Features","text":"<ul> <li>Breaking changes<ul> <li>(None currently planned)</li> </ul> </li> <li>Major features<ul> <li> Plotting (with hillshade background...?)</li> <li> Heat flow &amp; Curie depths</li> <li> Add MAVEN magnetometer module</li> </ul> </li> <li>Known bugs<ul> <li> boug data has weird wraparound at lon 180 -- reproduce, run <code>import redplanet as rp; rp.Crust.boug.load('Genova2016'); d = 1.e-6; print(rp.Crust.boug.get(-180 + d, 0)); print(rp.Crust.boug.get( 180 - d, 0))</code><ul> <li>although I'm pretty sure this is a bug in the data itself, not in the code...?</li> </ul> </li> </ul> </li> <li>Minor functional changes/updates<ul> <li> Update crater database with new IAU additions<ul> <li>Redplanet currently uses a database up to 2024-11-26 with 1218 craters -- as of 2025-02-27, there are 1231 craters (13 additions).</li> </ul> </li> </ul> </li> <li>Software changes<ul> <li> Auto-generated changelogs from \"conventional commits\" standard<ul> <li>\"commitizen\" seems promising</li> <li>thoughts of a robot</li> </ul> </li> <li> Publish to conda forge (tutorial)<ul> <li>I think it needs to be added/approved manually first, then I can automate it with a GH action</li> </ul> </li> <li> Add GitHub actions for CI/CD<ul> <li>Specifically, GH actions for running tests with uv, and publishing the site (see justfile for more specific commands!)</li> </ul> </li> <li> Website: fix <code>mkdocstrings</code> config so it selectively inspects objects with the <code>@substitute_docstring</code> decorator, instead of forcing dynamic analysis for everything</li> <li> Website: find a way to do citations via bibtex in the website itself, preferrably with footnotes<ul> <li>maybe use <code>shyamd-mkdocs-bibtex</code>?</li> </ul> </li> <li> Switch from <code>pandas</code> to <code>polars</code> to save a lot of space and slight performance improvements (move pandas to optional dependecy group)</li> <li> Change all <code>loader</code> modules so they have an additional semi-private method which returns the respective <code>GriddedData</code> object, which is then assigned to the global variable by the <code>load()</code>/<code>load(...)</code>/<code>_load()</code> method. This is more clean and extensible in edge cases, e.g. <code>Crust.moho</code> wants the pysh topo model to make a crthick model (kind of).</li> <li> Move <code>DatasetManager</code> to <code>redplanet.helper_functions</code>?</li> <li> Add <code>plotly</code> as an alternative engine for <code>redplanet.plot(...)</code>.</li> </ul> </li> </ul>"},{"location":"home/about/changelog/#2-changelog","title":"[2] Changelog","text":"<p>RedPlanet follows the Semantic Versioning standard. In short, this means that version numbers follow the pattern <code>MAJOR.MINOR.PATCH</code>, where <code>MAJOR</code> is incremented for breaking changes (i.e. not backwards compatible), <code>MINOR</code> is incremented for new features, and <code>PATCH</code> is incremented for bug fixes.</p> Complete rewrite in 2024 September &amp; deleting v1.0.0 <p>I completely rewrote this project in 2024 September, erasing the entire git history and restarting from scratch. On PyPI, I deleted the only version which which was ever published (v1.0.0), so it's impossible to download now (as opposed to \"yanking\" which would allow for downloading if the exact version were accidentally requested). An archive of the old repo is available here: https://github.com/Humboldt-Penguin/redplanet_archive-240910</p> <p> </p> <p>self note:</p> <ul> <li>Take inspiration from the following:<ul> <li>mihon (this is much more comprehensible)</li> <li>shtools</li> <li>uv (but this is only on github) \u2014 but tbh, i don't really love these...? it's always been a bit confusing to parse</li> </ul> </li> </ul> <p> </p> <p>Bonus: These badges track PyPI downloads, but they're quite misleading since I'm pretty sure my automated tests with GitHub actions, my online Google Colab demo, and/or some other source are wildly inflating the download count. Still fun to see though :)</p>"},{"location":"home/about/contact/","title":"Contact","text":"<p>Feel free to contact me at zain.eris.kamal@rutgers.edu. I'm more than happy to take any questions, discussion, feedback, or criticism. I also welcome any requests to share/explain code or help adapt it for your purposes \u2014 RedPlanet is the tool I wish I had when I started in this field a few years ago, and I'd love to play a part in lowering barriers to entry for anyone else who has passion/interest in this field :)</p> <p>You can see more of my work here: github.com/humboldt-penguin.</p> <p> </p> <p>Huge thanks to my incredible advisor Prof. Lujendra Ojha for all his support, guidance, patience, and kindness over the past four years.</p>"},{"location":"home/about/contributing/","title":"Contributing","text":"<p>This page is for anyone who wants to contribute to RedPlanet's code.</p> <p>We assume you're familiar with GitHub and Git. If not, learn about them here.</p> <p>If you're not comfortable with this process, feel free to contact us by email or open an issue on GitHub \u2014 we'd happy to implement your suggestions!</p>"},{"location":"home/about/contributing/#1-developer-tools","title":"[1] Developer Tools","text":""},{"location":"home/about/contributing/#11-prerequisites","title":"[1.1] Prerequisites","text":"<p>Any operating system should be fine:</p> OS Instructions Linux/MacOS Everything should work out of the box. Windows Please just use WSL (Windows Subsystem for Linux), it takes a few minutes to set up and will make anything programming-related exponentially easier. Nix (OS / package manager) We use this ourselves since it offers the most reliable/reproducible/sandboxed development environment. Make sure flakes are enabled, and run <code>just activate-devshell</code> (or <code>nix develop</code>) to enter the development environment based on <code>flake.nix</code> and <code>flake.lock</code>. <p> </p> <p>Please install the following tools (these are fairly lightweight, easy to uninstall, and will never permanently alter you system in any way \u2014 I'd never ask you to install something I wouldn't be comfortable with on my own personal computer!):</p> <ol> <li><code>uv</code> by Astral for running/managing Python environments.</li> <li><code>just</code> by Casey Rodarmor as a lightweight/basic command runner, very similar to GNU Make / Makefiles. You can see the exact commands in the <code>.justfile</code>, or list the recipes by running <code>just</code>:</li> </ol> <pre><code>Available recipes:\n    [Help]\n    help              # List all recipes (or just run `just`).\n\n    [Development shell via Nix package manager]\n    activate-devshell # Activate interactive development shell with uv (remember to `exit` when done) \u2014 we recommend getting into the habit of using this recipe over plain `nix develop` since it incorporates guard rails against entering multi-nested devshells.\n    update-flake      # Update flake. (check for `uv` updates in nixpkgs here: https://github.com/NixOS/nixpkgs/blob/nixpkgs-unstable/pkgs/by-name/uv/uv/package.nix )\n\n    [Dependencies]\n    sync-venv         # Sync the project's environment (`.venv/`) with exact dependencies in the lockfile (`uv.lock`), including installing this project in editable mode. If `.venv/` doesn't exist, it will be created.\n    update-lockfile   # Update lockfile (`uv.lock`) with the latest versions of all dependencies. This does NOT install or modify `.venv/` \u2014 for that, see `sync-venv`.\n\n    [Test]\n    test              # Run tests.\n    test-verbose      # Run tests, do not suppress print statements.\n\n    [Website]\n    serve-site        # Start the live-reloading docs server locally (see: http://localhost:8000/ ).\n    deploy-site       # Deploy to GitHub Pages.\n\n    [Publish]\n    tag               # Create an annotated git tag with version from `pyproject.toml` \u2014 NOTE: this triggers a PyPI release when pushed! You should (1) push and verify tests passing in GitHub Actions; (2) update version manually in `pyproject.toml` and automatically in `uv.lock` (`just test`), then commit; (3) merge to main, then `just tag`; (4) double check, then push commit + tag.\n\n    [misc]\n    clean             # Clean up miscellaneous build/artifact files.\n</code></pre> <p> </p>"},{"location":"home/about/contributing/#12-install-project-locally","title":"[1.2] Install Project Locally","text":"<p>Run <code>just sync-venv</code> (which calls <code>uv sync --all-extras --all-groups</code> under the hood) to sync the project's environment (<code>.venv/</code>) with exact dependencies in the lockfile (<code>uv.lock</code>). This will also install <code>redplanet</code> in editable mode (corresponding to <code>pip install -e .</code>), so you can make changes to the code and see them reflected immediately. If <code>.venv/</code> doesn't exist, it will be created.</p> <p> </p>"},{"location":"home/about/contributing/#2-how-to-modifycontribute-code","title":"[2] How to Modify/Contribute Code","text":"<p>We assume you've followed the steps above to set up your development environment.</p>"},{"location":"home/about/contributing/#21-experienced-users","title":"[2.1] Experienced Users","text":"<p>For experienced users, here's a quick guide:</p> <ul> <li>Please make all changes on the <code>develop</code> branch.</li> <li>Ensure all tests are passing locally (<code>just test</code>) and in the GitHub Actions of your forked repository upon pushing.</li> <li>Make a pull request to the <code>develop</code> branch of the main repository.</li> </ul> <p> </p>"},{"location":"home/about/contributing/#22-beginners","title":"[2.2] Beginners","text":"<p>For beginners, here's a step-by-step guide:</p> <ol> <li>Fork the repository.<ol> <li>Sign into your GitHub account, go to our repository, and click the \"Fork\" button in the top right corner.</li> <li>On your local machine, <code>git clone ...</code> your forked repository. Enter the repository with <code>cd redplanet</code>.</li> </ol> </li> <li>Make changes on the <code>develop</code> branch.<ol> <li>By default you are on the <code>main</code> branch, which reflects the latest stable release. Switch to the development branch with <code>git checkout develop</code>, which contains the latest development changes.</li> <li>Create a new branch for your changes with <code>git checkout -b your-contribution-name</code>.</li> <li>Implement and commit your changes.<ul> <li>We encourage you to use Conventional Commit Messages (cheatsheets: [1], [2]) for best practices/standardization, although it's not required.</li> </ul> </li> <li>Ensure all tests are still passing with <code>just test</code>.</li> <li>Push your changes to your fork with <code>git push origin your-contribution-name</code>. See the \"Actions\" tab on your forked repository to see if tests are passing on all python versions and platforms.</li> </ol> </li> <li>When your changes are ready to be incorporated into the main repository, make a pull request.<ol> <li>Go to your forked repository on GitHub and click the \"New pull request\" button.</li> <li>Describe what you changed and why.</li> <li>Submit the pull request.</li> <li>We will review your changes and provide feedback if necessary.</li> </ol> </li> </ol>"},{"location":"home/about/license/","title":"License","text":"<p>The MIT license is a permissive license that allows commercial use and private modification/redistribution as long as the original authors are credited.</p> <p> </p> <pre><code>MIT License\n\nCopyright (c) 2023-2025 Zain Kamal &lt;zain.eris.kamal@rutgers.edu&gt;\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"home/quick_start/installation/","title":"Installation","text":""},{"location":"home/quick_start/installation/#1-system-requirements","title":"[1] System Requirements","text":"<p>RedPlanet is supported on the following platforms, as verified by our automated tests on GitHub Actions:</p> <ul> <li>Operating Systems \u2014 Linux, MacOS, and Windows</li> <li>Python Version \u2014 3.10 to 3.12<ul> <li>We plan to add support for 3.13 once pyshtools is updated.</li> <li>To see the official support timeline for all versions of Python, look here or here.</li> </ul> </li> </ul> <p>If you're having installation issues or want to request support for earlier versions of Python, feel free to send an email or open an issue on GitHub. It might only take a few minutes to add compatibility.</p> <p> </p>"},{"location":"home/quick_start/installation/#2-installation","title":"[2] Installation","text":"<p>For beginners, I wrote a guide which explains the concepts, steps, and suggested tools for installing Python and packages (relevant xkcd). For intermediate/advanced users, I recommend checking out a new tool called <code>uv</code> by Astral.</p> <p> </p> <p>Past that, install from PyPI with <code>pip install redplanet</code>.</p> <p>We'd be happy to upload to conda-forge upon request, feel free to send an email or open an issue on GitHub.</p> <p> </p>"},{"location":"home/quick_start/installation/#3-dependencies","title":"[3] Dependencies","text":"\"Installation Size\" <p>For convenience, we provide an estimated size for each package \u2014 these are ROUGH ESTIMATES and can vary wildly based on your system and combinations of dependency groups (e.g. <code>pyshtools</code> requires <code>scipy</code>, so we can't remove the latter without removing the former):</p> <ul> <li>Low: &lt; 5MB</li> <li>Medium: 5-50MB</li> <li>High: &gt; 50MB</li> </ul> <p>For reference, installing ALL dependencies (including developer dependencies, which normal users will never need) in a fresh Python environment takes ~1GB.</p>"},{"location":"home/quick_start/installation/#31-required-dependencies","title":"[3.1] Required Dependencies","text":"<p>Included in <code>pip install redplanet</code></p> Package Purpose Minimum Version Installed Size numpy Essential numerical computing 2.1.1 High pyshtools Spherical harmonic operations (moho &amp; magnetic field) 4.13.1 Medium pandas Tabular/2D data (GRS &amp; magnetic source depths) 2.2.2 High python-calamine Excel file parsing (engine for pandas) 0.3.1 Low cartopy Defining the Martian ellipsoid and solving geodesic problems 0.24.1 Medium scipy Scientific computing algorithms 1.14.1 High xarray Multi-dimensional data handling 2024.9.0 Medium xxhash Fast hashing for data validation 3.5.0 Low <p> </p>"},{"location":"home/quick_start/installation/#32-optional-dependencies","title":"[3.2] Optional Dependencies","text":"<p>For additional features, you'll need to install additional packages.</p> <p> </p>"},{"location":"home/quick_start/installation/#321-interactiveplotting-recommended","title":"[3.2.1] Interactive/Plotting (recommended)","text":"<p><code>pip install \"redplanet[interactive]\"</code></p> Package Purpose Minimum Version Installed Size jupyter Interactive notebooks, extremely useful 1.1.1 High matplotlib Static 2D plots 3.9.2 Medium plotly Interactive 2D/3D plots 5.24.1 Medium"},{"location":"home/quick_start/installation/#322-reproduce-datasets","title":"[3.2.2] Reproduce Datasets","text":"<p><code>pip install \"redplanet[generate-datasets]\"</code></p> Package Purpose Minimum Version Installed Size dask Parallel computing (large DEM datasets) 2024.9.0 Medium rioxarray Geospatial raster processing (reprojecting DEM maps) 0.17.0 Medium zarr Chunked/compressed array storage (large DEM datasets) 2.18.3 Low <p> </p> <p>Note you can install both sets of optional dependencies with a single command: <code>pip install \"redplanet[interactive,generate-datasets]\"</code>.</p>"},{"location":"home/quick_start/overview/","title":"Overview","text":"<p>bwaaa</p> <p>4 modules for users:</p> <ol> <li>User Config<ul> <li>Whenever you run code that requires a dataset, RedPlanet will (1) check if the file is in your local cache and has the correct hash, and if not then (2) download the file.</li> <li>You can specify various options like where the data is stored, how file integrity is checked, etc.</li> </ul> </li> <li>Datasets<ul> <li>There are 2 general types of datasets:<ol> <li>Raster datasets (i.e. regular 2D grids, or \"pixels\"), where you must <code>load</code> a model before using the <code>get</code> function to access points/swaths of data. For implementation details, see <code>src/redplanet/helper_functions/GriddedData.py</code>.<ul> <li>Topography / DEM (<code>Crust.topo</code>)</li> <li>Mohorovi\u010di\u0107 Discontinuity / Crustal Thickness (<code>Crust.moho</code>)</li> <li>Bouguer Anomaly (<code>Crust.boug</code>)</li> <li>Spherical Harmonic Models (<code>Mag.sh</code>)</li> <li>Gamma-Ray Spectrometer (<code>GRS</code>) \u2014 this is a special case where no <code>load</code> function is needed, it's loaded upon first access.</li> </ul> </li> <li>Point datasets, no need to <code>load</code> before use.<ul> <li>Craters (<code>Craters</code>)</li> <li>Dichotomy (<code>Crust.dichotomy</code>)</li> <li>Magnetic Source Depths (<code>Mag.depth</code>)</li> </ul> </li> </ol> </li> </ul> </li> <li>Analysis<ul> <li>Various analysis tools</li> </ul> </li> <li>Helper Functions<ul> <li>Miscellaneous convenience functions</li> </ul> </li> </ol>"},{"location":"supplemental/","title":"Supplemental Materials","text":"<p>We try to provide full explanations and citations in the documentation for each individual function (see Usage section), but some topics need a bit more space to explain. This section is for those topics.</p> <p> </p> <ul> <li>Impact Demagnetization<ul> <li>Explaining and deriving our analytical model for calculating subsurface impact pressures.</li> <li>Used in:<ul> <li><code>redplanet.analysis.impact_demag.compute_pressure(...)</code>.</li> </ul> </li> </ul> </li> <li>Radial Profile<ul> <li>Visual explanation of how we compute radial/cross-sectional averages while respecting geodesic distances.</li> <li>Used in:<ul> <li><code>redplanet.analysis.radial_profile.get_concentric_ring_coords(...)</code></li> <li><code>redplanet.analysis.radial_profile.get_profile(...)</code></li> </ul> </li> </ul> </li> <li>Plotting<ul> <li>Tips, code snippets, and resources on plotting data with <code>matplotlib</code> (unfortunately it's less straightforward than you might expect \u2014 we plan on adding a plotting feature to RedPlanet in the future, but it will always be helpful to know how to do it yourself).</li> </ul> </li> </ul>"},{"location":"supplemental/impact_demagnetization/","title":"Impact Demagnetization","text":"<p>MOTIVATION \u2014 Previous works calculate shock pressures from an impact without simulation tools like iSALE [1-3]. However, I personally found the explanation of methods to be very difficult to follow and contradictory in some places.</p> <p>This document offers a simplified explanation/overview which a beginner could follow. See the original works for underlying citations and further explanations.</p> <p> </p>"},{"location":"supplemental/impact_demagnetization/#1-observed-crater-diameter-radius-of-projectile","title":"[1] Observed Crater Diameter  Radius of Projectile","text":"<p>The Holsapple [1993] scaling relationship is</p> \\[ \\begin{equation}     D_{tr} =( 0.7576) \\cdot \\left( D_{o}^{0.921}\\right) \\cdot \\left( D_{*}^{0.079}\\right), \\end{equation} \\] <p>where:</p> <ul> <li>\\(D_o\\) \u2014 Observed crater diameter.<ul> <li>Note: this is the only crater-dependent input for our calculation (not counting crustal density at that location).</li> </ul> </li> <li>\\(D_*\\) \u2014 Transition diameter from simple to complex crater.<ul> <li>Assumed 7km for Mars (Melosh, 1989).</li> </ul> </li> <li>\\(D_{tr}\\) \u2014 Transient crater diameter.</li> </ul> <p> </p> <p>From this, we can use the Schmidt and Housen [1987] relationship</p> \\[ \\begin{equation}     E_{\\text{proj}} = \\left(\\frac{1}{0.2212} \\cdot D_{tr} \\cdot v_{\\text{proj}}^{0.09} \\cdot g^{0.22} \\right) ^{1/0.26}, \\end{equation} \\] <p>where:</p> <ul> <li>\\(v_{\\text{proj}}\\) \u2014 Projectile velocity.<ul> <li>The majority of impact craters on Mars are formed by heliocentric projectiles with velocity 8-12 km/s (Neukum &amp; Wise, 1976).</li> </ul> </li> <li>\\(g\\) \u2014 Surface gravity of Mars.<ul> <li>\\(3.72076 \\ \\text{m} / \\text{s}^2\\)</li> </ul> </li> <li>\\(E_{\\text{proj}}\\) \u2014 Kinetic energy of projectile.</li> </ul> <p> </p> <p>Now assume the projectile is spherical and composed of basalts. This lets us write out a few trivial relations:</p> <ul> <li>\\(\\rho_{\\text{proj}} = 2,900 \\ \\text{kg} / \\text{m}^3\\)</li> <li>\\(V_{\\text{proj}} = \\tfrac{4}{3} \\pi r_{\\text{proj}}^2\\)</li> <li>\\(E_{\\text{proj}} = \\tfrac{1}{2} M_{\\text{proj}} v_{\\text{proj}}^2\\)</li> </ul> <p>We combine all of these through \\(\\rho_{\\text{proj}} = M_{\\text{proj}} / V_{\\text{proj}}\\) and solve for the radius of the projectile to find:</p> \\[ \\begin{equation}     r_{\\text{proj}} = \\left( \\frac{3E_{\\text{proj}}}{2 \\pi \\rho_{\\text{proj}} v_{\\text{proj}}^2} \\right) ^{1/3}. \\end{equation} \\] <p> </p>"},{"location":"supplemental/impact_demagnetization/#2-shock-wave-pressures","title":"[2] Shock Wave Pressures","text":""},{"location":"supplemental/impact_demagnetization/#21-generalized-hugoniot-equation","title":"[2.1] Generalized Hugoniot Equation","text":"<p>Consider the momentum jump condition from the Rankine-Hugoniot relations</p> \\[ \\begin{equation}     P - P_0 = \\rho_{\\text{crust}} \\cdot u_{sw} \\cdot u_p, \\end{equation} \\] <p>where:</p> <ul> <li>\\(P\\) \u2014 Pressure behind the shock front (compressed region).</li> <li>\\(P_0\\) \u2014 Pressure ahead of the shock front (unshocked region), i.e. ambient/initial pressure.<ul> <li>In this case, \\(P_0\\) is atmospheric pressure which is negligible.</li> </ul> </li> <li>\\(\\rho_{\\text{crust}}\\) \u2014 Density of the target material, i.e. Martian crust.</li> <li>\\(u_{sw}\\) \u2014 Shock wave velocity, the speed at which the shock front propagates through the material.</li> <li>\\(u_p\\) \u2014 Particle velocity, the speed at which particles in the material move due to the passage of the shock wave.</li> </ul> <p> </p> <p>Most materials exhibit a linear relationship between shock wave velocity and particle velocity (up to moderate pressures arounda few hundred GPa) according to laboratory experiments, modeled as</p> \\[ \\begin{equation}     u_{sw} = C + S u_p, \\end{equation} \\] <p>where:</p> <ul> <li>\\(C\\) \u2014 Represents the bulk sound speed (i.e. speed at which small-amplitude sound waves travel through the material under uncompressed/ambient conditions).<ul> <li>Previous works give a wide range of values (\\(2.6\\), \\(3\\), and \\(3.5\\) \\(\\text{km} / \\text{s}\\)), some higher (?).</li> <li>The pressures we're interested in are about less than or equal to the Hugoniot elastic limit (the point where a material transitions from a purely elastic state to an elastic-plastic state), so we use this constant to model the propogation of shock waves for the entirety of this work.</li> </ul> </li> <li>\\(S\\) \u2014 Characterizes the compressibility of the material under shock loading (higher values correspond to a material that is harder to compress at high pressures relative to its ambient compressibility).<ul> <li>Previous works agree around \\(1.5\\).</li> </ul> </li> </ul> <p> </p> <p>Combining this with the Hugoniot equation, the total shock pressure at some point in the Crust is given by:</p> \\[ \\begin{equation}     P = \\rho_{\\text{crust}} \\cdot u_p \\cdot (C + S u_p). \\end{equation} \\] <p>The primary source of depth-based variations in shock pressure is due to variations in particle velocity (\\(u_p\\)), which is discussed next.</p> <p> </p>"},{"location":"supplemental/impact_demagnetization/#22-direct-shock-pressure-ie-adding-depth-dependence","title":"[2.2] Direct Shock Pressure (i.e. Adding Depth Dependence)","text":""},{"location":"supplemental/impact_demagnetization/#221-near-shock","title":"[2.2.1] Near-shock","text":"<p>Previous impact simulation work shows that upon contact and compression, the initial convergence of shock waves creates a region of nearly uniform shock pressures known as the \"isobaric core\" (denoted \"IC\"). The volume of this region is roughly proportional to the dimensions of the projectile if it were completely buried (see fig. 1 in a later section for a basic diagram). We model this with:</p> \\[ \\begin{equation}     u_p( r \\leq R_{IC} ) = u_{IC}, \\end{equation} \\] <p>where:</p> <ul> <li>\\(r\\) \u2014 Distance from the center of the isobaric core.</li> <li>\\(R_{IC}\\) \u2014 Radius of the IC.<ul> <li>As previously explained, we assume \\(R_{IC} \\approx r_{\\text{proj}}\\) (for reference, some works say \\(R_{IC} \\approx 0.7 \\cdot r_{\\text{proj}}\\); we assume they're the same size, it doesn't make a huge difference).</li> </ul> </li> <li>\\(u_{IC}\\) \u2014 Particle velocity in the isobaric core.<ul> <li>When the impactor and target have similar mechanical properties, the particle velocity is about half the impactor velocity, i.e. \\(u_{IC} = \\tfrac{1}{2} v_{\\text{proj}}\\).</li> </ul> </li> </ul> <p> </p>"},{"location":"supplemental/impact_demagnetization/#222-far-shock","title":"[2.2.2] Far-shock","text":"<p>Outside the IC, the particle velocity decreases with distance according to a power law</p> \\[ \\begin{equation}     u_p( r &gt; R_{IC} ) = u_{IC} \\cdot \\left[ \\frac{r}{R_{IC}} \\right] ^{-n}, \\end{equation} \\] <p>where:</p> <ul> <li>\\(n\\) \u2014 Exponential decay constant.<ul> <li>This varies widely between works. Melosh 1989 uses a constant \\(n=1.87\\), while Mitani 2003 uses variable \\(n\\) for different pressure regions. We use the former for our purposes ('intermediate' impacts where \\(D_o &lt; 500 \\ \\text{km}\\), and we're only concerned about furthest demagnetization extent).</li> </ul> </li> </ul> <p>Many works approximate pressure decay using a power law (i.e., replacing \\(u_{IC}\\) with \\(P_{IC}\\)). However, the earliest reference I found attributes this decay to particle velocity instead (see page 18 of Perret &amp; Bass, 1975 [doi]), with the pressure-based version being an approximation. This likely makes little difference, but it's worth noting.</p> <p> </p>"},{"location":"supplemental/impact_demagnetization/#223-putting-it-all-together","title":"[2.2.3] Putting it all Together","text":"<p>Substitute these \\(u_p(r)\\) into equation 6 to find pressure from the initial shock wave as a function of distance from the center of the isobaric core. This is denoted \\(P_{\\text{direct}}(r)\\), since we apply some corrections for reflected waves in the next section.</p> <p>For convenience, here's the full equation in terms of known values, although it may not render correctly based on where you're viewing this.</p> \\[ \\begin{equation} \\begin{aligned}     P_{\\text{direct}}( r) &amp; =\\begin{cases}     \\{r \\leq r_{\\text{proj}}\\} : &amp; \\rho _{\\text{crust}} \\cdot \\left(\\tfrac{1}{2} v_{\\text{proj}}\\right) \\cdot \\left( C+S\\cdot \\tfrac{1}{2} v_{\\text{proj}}\\right)\\\\     \\{r &gt;r_{\\text{proj}}\\} : &amp; \\rho _{\\text{crust}} \\cdot \\left(\\tfrac{1}{2} v_{\\text{proj}}\\left[\\frac{r}{r_{\\text{proj}}}\\right]^{-n}\\right) \\cdot \\left( C+S\\cdot \\tfrac{1}{2} v_{\\text{proj}}\\left[\\frac{r}{r_{\\text{proj}}}\\right]^{-n}\\right) \\end{cases} \\end{aligned} \\end{equation} \\] <p> </p>"},{"location":"supplemental/impact_demagnetization/#23-reflected-shock-wave-correction-surface-boundary-condition","title":"[2.3] Reflected Shock Wave Correction (Surface Boundary Condition)","text":"<p>During an impact, the induced pressure at the surface must drop to zero. This causes the shock wave to reflect, generating a rarefaction wave that travels back and interacts with the initial shock wave. If the rarefaction wave arrives before the peak pressure is reached (this period is known as the \"rise time\"), it can interfere with the buildup of the pressure wave and reduce the peak pressure achieved. See figure 1 below for a basic diagram.</p> <p>Figure 1: Path of direct and reflected shock waves to a given point.</p> <p> </p> <p>To calculate this reduction, we begin by inferring some basic geometric relationships,</p> \\[ \\begin{equation} \\begin{aligned}     R_{\\text{dir}}( x,y) &amp; =\\sqrt{x^{2} +( y-R_{IC})^{2}}\\\\     R_{\\text{ref}}( x,y) &amp; =\\sqrt{x^{2} +( y+R_{IC})^{2}}, \\end{aligned} \\end{equation} \\] <p>where:</p> <ul> <li>\\(R_{\\text{dir}}, R_{\\text{ref}}\\) \u2014 Distances traveled by the direct and reflected waves respectively.</li> <li>\\(x,y\\) \u2014 Horizontal and vertical distances from the impact point respectively.</li> </ul> <p> </p> <p>At a given point, the difference in time between the arrival of the direct and reflected pressure waves is denoted:</p> \\[ \\begin{equation}     \\Delta t = \\frac{ R_\\text{ref} - R_\\text{dir} }{C}, \\end{equation} \\] <p>whereas the rise time (the time it takes for the impact to reach peak pressure) is:</p> \\[ \\begin{equation}     \\tau_{\\text{rise}} = \\frac{ r_{\\text{proj}} }{ v_{\\text{proj}} }. \\end{equation} \\] <p> </p> <p>As before, the shock pressure is unaffected when \\(\\Delta t \\geq \\tau_{\\text{rise}}\\). However, when \\(\\Delta t &lt; \\tau_{\\text{rise}}\\), we reduce the direct pressure by the reflected wave attenuated by the additional distance traveled. Putting everything together, the effective subsurface shock pressure is given by:</p> \\[ \\begin{equation}     P_{\\text{eff}} = \\begin{cases}     \\{\\Delta t \\geq \\tau _{\\text{rise}}\\} : &amp; P_{\\text{direct}}( R_{\\text{dir}})\\\\     \\{\\Delta t &lt; \\tau _{\\text{rise}}\\} : &amp; P_{\\text{direct}}( R_{\\text{dir}}) -P_{\\text{direct}}( R_{\\text{ref}}) \\cdot \\left( 1-\\frac{\\Delta t}{\\tau _{\\text{rise}}}\\right) .     \\end{cases} \\end{equation} \\] <p> </p> <p> </p>"},{"location":"supplemental/impact_demagnetization/#references","title":"References:","text":"<ul> <li>[1] Mohit &amp; Arkani-Hamed 2003<ul> <li>https://files.catbox.moe/kbrqh9.pdf</li> </ul> </li> <li>[2] Shahnas &amp; Arkani-Hamed 2007<ul> <li>https://files.catbox.moe/bqeh07.pdf</li> </ul> </li> <li>[3] Melosh 2011<ul> <li>https://sseh.uchicago.edu/doc/Melosh_ch_6.pdf</li> </ul> </li> </ul>"},{"location":"supplemental/plotting/","title":"Plotting","text":"<p>For more info on making publication quality plots, we highly recommend the PySHTools documentation \u2014 see the \"Plotting maps\" section on this page (direct link).</p> <p>TODO: documentation for <code>redplanet.plot</code> module.</p> <p>Here's some boilerplate for making/configuring plots with <code>matplotlib</code>.</p> <p> </p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\nfrom redplanet import Crust\n\n\n\n\n\nlon_bounds = [-180, 180]\nlat_bounds = [-90 , 90]\n\nlons = np.linspace(lon_bounds[0], lon_bounds[1], 1000)\nlats = np.linspace(lat_bounds[0], lat_bounds[1], 1000)\n\nCrust.topo.load('DEM_463m')\ndat_topo = Crust.topo.get(lons, lats)\n\n\n\n\n\n'''template for plotting stuff:'''\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# ax.set_title('Bouguer Gravity Anomaly')\nax.set_xlabel('Longitude')\nax.set_ylabel('Latitude')\n\nim = ax.imshow(\n    dat_topo / 1.e3,\n    cmap   = 'RdBu_r',\n    # cmap   = 'Greys',\n    origin = 'lower',\n    aspect = 'auto',  ## 'auto' makes rectangular pixels, 'equal' makes square pixels\n    extent = [lon_bounds[0], lon_bounds[1], lat_bounds[0], lat_bounds[1]],\n)\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"3%\", pad=0.2)  ## `size` sets colorbar width to X% of main axes; `pad` sets separation between axes and colorbar to X inches\ncbar = fig.colorbar(im, cax=cax)\ncbar.set_label('Topography (km)')\n\nplt.show()\n</code></pre>"},{"location":"supplemental/radial_profile/","title":"Radial Profile","text":"<p>THIS IS A DRAFT</p> <p>Implementation details/notes:</p> <ul> <li> <p>Methods:</p> <ul> <li>Rings are generated with the <code>cartopy.geodesic.Geodesic.circle</code> method which solves the direct geodesic problem to generate a circle of equidistant points from a center point.<ul> <li>The reference ellipsoid is defined as:<ul> <li>[Params:]<ul> <li>Semimajor axis: 3395428 m</li> <li>Flattening: 0.005227617843759314</li> </ul> </li> <li>[Citation:]<ul> <li>Ardalan, A. A., Karimi, R., &amp; Grafarend, E. W. (2009). A New Reference Equipotential Surface, and Reference Ellipsoid for the Planet Mars. Earth, Moon, and Planets, 106, 1-13. https://doi.org/10.1007/s11038-009-9342-7</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Reasoning:</p> <ul> <li>Q: Why generate / average over multiple rings?<ul> <li>I don't think you can just generate a single geodesic circle at desired radius and interpolate lon/lat coordinates from the center to each point on the circle, since that's not the correct geodesic path!!!</li> <li>My method of averaging over concentric rings is more complicated than the above but significantly more correct (i.e. geometrically perfect, I think). Not sure how much error is practically introduced by the prior method though.</li> </ul> </li> <li>Q: How do we determine the number of points per ring?<ul> <li>[Method 1, Fig 1 &amp; Fig 2] Easy/straightforward method is for every ring to have a constant number of points (cartopy default is 180). The drawback is either inner rings have aggressively too many points or outer rings have too few points, which can get unnecessarily costly/annoying/inconsistent.<ul> <li>The example below took 0.878 seconds (just for data generation, not plotting) for 7,200 points.</li> </ul> </li> <li>[Method 2, Fig 3 &amp; Fig 4] A more complex but efficient method is to make it so there's a constant distance between points on each ring (default is 5km). This way, we don't have to worry about tweaking the number of points per ring to eliminate inefficiency/inconsistency in the inner/outer rings -- i.e. run and forget about it.<ul> <li>The example below took 0.673 seconds for 4,933 points.</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p> </p> <p> </p>"},{"location":"supplemental/radial_profile/#figures","title":"Figures","text":"<p> Figure 1:         180 points per ring.     </p> <p> </p> <p> Figure 2:         180 points per ring.     </p> <p> </p> <p> Figure 3:         5km between points on each ring.     </p> <p> </p> <p> Figure 4:         5km between points on each ring.     </p> <p> </p>"},{"location":"tutorials/","title":"Tutorials &amp; Guides (UNFINISHED)","text":""},{"location":"tutorials/#1-getting-started","title":"[1] Getting Started","text":"<ul> <li> <p> Online Demo</p> <p> </p> <p>Try RedPlanet in your browser without installing anything.</p> </li> <li> <p> 3D Print a Crater</p> <p> </p> <p>Learn RedPlanet by generating 3D print files your favorite crater/region!</p> </li> <li> <p> How to Install/Use Python</p> <p> </p> <p>Overview of concepts, tools, best-practices, and advice for installing Python and managing packages.</p> </li> </ul> <p> </p>"},{"location":"tutorials/#2-basics-of-redplanet","title":"[2] Basics of RedPlanet","text":"<ul> <li> <p> Radial Profiles</p> <p> </p> <p>Average cross-section of a crater.</p> </li> <li> <p>Plotting (coming soon)</p> </li> <li> <p>Impact demagnetization (coming soon)</p> </li> <li> <p>Heat flow &amp; Curie depths (coming soon)</p> </li> </ul> <p> </p>"},{"location":"tutorials/#3-advanced-analysis","title":"[3] Advanced Analysis","text":"<ul> <li>Using craters as \"snapshots\" of ancient Mars (coming soon)</li> </ul>"},{"location":"tutorials/#4-external-resources-opens-in-new-tab","title":"[4] External Resources (opens in new tab)","text":"<ul> <li> <p> Mars QuickMap</p> <p> </p> <p>Lightweight/interactive mapping tool with various datasets, completely in your browser! This is my personal go-to. Tip: use bit.ly/marsquickmap for a preconfigured link that disables the default layers.</p> </li> <li> <p> PySHTools Tutorials</p> <p> </p> <p>PySHTools is a python package for spherical harmonic computation/analysis in planetary sciences. Their \"Tutorials &amp; Guides\" section is an amazing resource for learning both the package and spherical harmonics in general.</p> </li> </ul>"},{"location":"tutorials/basics/radial_profile/","title":"Radial Profile","text":"<p>TODO: move this entirely to a colab notebook, and only keep some key figures on this page. \u2014 also add more code to get radial averages (maybe even with errors), not just the coordinates.</p> <p>Here's a sample plot of output ring coordinates around Newton crater, where each ring is a different color and we dramatically undersample the points on each ring for clarity (20 rings, 10km between points on each ring):</p> <p>The code to generate this plot is as follows:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport redplanet as rp\n\n## get crater data\ncrater = rp.Craters.get(name='Newton', as_dict=True)[0]\n\n## get concentric ring coordinates\nring_radius_km__per_ring, ring_coords__per_ring = rp.analysis.radial_profile.get_concentric_ring_coords(\n    lon = crater['lon'],\n    lat = crater['lat'],\n    radius_km = (crater['diam'] / 2) * 2.5,\n    num_rings = 20,\n    dist_btwn_points_km = 10,\n)\n\n## plot hillshade (base)\nr = 10\nlons = np.linspace(crater['lon']-r, crater['lon']+r, 1000)\nlats = np.linspace(crater['lat']-r, crater['lat']+r, 1000)\nrp.Crust.topo.load('DEM_463m')\n\nfig, ax = rp.plot(\n    lons, lats,\n    dat = rp.Crust.topo.get(lons, lats),\n    figsize = (7,7),\n    hillshade = True,\n    cbar = False,\n    alpha_dat = 0,\n    alpha_hs = 0.5,\n    show = False,\n)\n\n## plot concentric rings\ncolors__per_ring = plt.cm.jet(\n    np.linspace(0, 1, len(ring_radius_km__per_ring))\n)\n\nfor i in range(len(ring_radius_km__per_ring)):\n    ax.scatter(\n        ring_coords__per_ring[i][:,0],\n        ring_coords__per_ring[i][:,1],\n        color = colors__per_ring[i],\n        s = 1,\n        alpha = 0.5,\n    )\n\nax.set_title(f'Concentric rings around {crater[\"name\"]} crater')\n\nplt.show()\n</code></pre>"},{"location":"tutorials/getting_started/3d_print/","title":"3D Print a Crater","text":"<p>This is a fun way to get started with RedPlanet. I made the code generalized and included comments so you can easily tinker around. If anything breaks, just refresh the page and everything will reset. For more info on how to use the Google Colab platform, see our Online Demo.</p> <p>If you're at Rutgers University in New Brunswick, here's a link to request a print at our MakerSpace on Livingston. It comes out to about $3-5 with PLA filament ($0.07/gram for dual-tone, I like the \"Neon City\" color), 5\"x5\" dimensions, and 10% infill.</p> <p> </p> Steps Example (Henry Crater) Pick any crater/region... Preview/customize a 3D contour... And generate a file you can send straight to your printer!"},{"location":"tutorials/getting_started/install_python/","title":"How to Install/Use Python","text":"<p>Unfortunately, Python is notorious for lacking a simple, out-of-the-box solution for installing and managing your packages and environments (relevant xkcd). I hope this explanation can help you understand why the best practices are what they are, get you up and running within a few minutes, and ultimately save you some time and frustration.(1) Let's get started!</p> <ol> <li>When I was first learning Python in high school, I messed up my Python installation so badly I had to completely reinstall my operating system. This is the guide I wish I had back then.</li> </ol> <p>If you're not ready to take the plunge (e.g. you want to experiment first, or you only need to run a few short code snippets), I'd highly encourage online tools like Google Colab which run completely in your browser and don't require any installation (see our \"Online Demo\" page for more info).</p> <p>If you're using Windows, I'd HIGHLY recommend using your built-in WSL (Windows Subsystem for Linux). It takes a few minutes to set up and will make every programming-related task exponentially easier, plus you can easily wipe/restore your environment without affecting your Windows installation at all in case anything ever goes wrong.</p> <p> </p>"},{"location":"tutorials/getting_started/install_python/#1-conceptsmotivation","title":"[1] Concepts/Motivation","text":"<p>The core Python language is occasionally updated to improve performance/security/features/bugs, and old versions are slowly deprecated according to a predetermined schedule. As such, it's highly recommended to use a recent version of Python which is still being monitored for security vulnerabilities. For an overview of which versions are currently supported, look here or here \u2014 for reference, RedPlanet currently supports Python 3.10 to 3.12.</p> <p>Python packages are external code libraries which extend the language's functionality (some ubiquitous examples are <code>numpy</code> for numerical computing, <code>pandas</code> for tabular data, <code>matplotlib</code> for plotting, and many more). The official \"index\" where Python packages are published/hosted/tracked/distributed is PyPI (Python Package Index) which is sufficient for most purposes. The official tool for installing packages on your computer is <code>pip</code> which is included with Python(1)\u2014 but don't go installing anything yet!</p> <ol> <li><code>pip</code> is a recursive acronym for \"pip installs packages\" \u2014 see the original 2008 blog post here.</li> </ol> <p>If you simply download Python from the official website and install packages with <code>pip</code>, there's a good chance you'd eventually run into some frustrating and unfixable issues. This is because by default, <code>pip</code> installs packages globally on your system, which can lead to conflicts between projects and unexpected behavior when different projects require different package versions.</p> <p>To avoid these pitfalls, it's best practice to isolate your project's dependencies from the global Python installation by creating separate virtual environments (in software/security, this principle is known as \"sandboxing\"). This ensures that dependencies remain consistent/trackable/reproducible across different systems, and your system-wide Python installation remains unaffected by project-specific changes.</p> <p> </p>"},{"location":"tutorials/getting_started/install_python/#2-tools-for-pythonpackage-management","title":"[2] Tools for Python/Package Management","text":"<p>Over the years, several tools have been developed to simplify the process of creating and managing virtual environments. Some popular options include:</p> <ul> <li><code>pip</code>/<code>venv</code> \u2014 Python's built-in solution (available from Python 3.3 onwards) for creating lightweight virtual environments.</li> <li><code>virtualenv</code>/<code>pipenv</code> \u2014 <code>virtualenv</code> predates <code>venv</code> and works with both Python 2 and 3, offering a flexible way to create isolated environments. <code>pipenv</code> build on this by integrating dependency management (via a <code>Pipfile</code>) with environment management, streamlining workflows and reducing the need for manual configuration.</li> <li>Conda \u2014 A package/environment manager with a broader scope than Python/<code>pip</code>, including support for multiple versions of Python, complex dependencies, and even programming languages other than Python. Conda has its own package index called conda-forge, but you still have access to everything on PyPI (just install <code>pip</code> in a Conda environment). Conda is only strictly necessary for tasks like GPU programming. In order to actually install/use Conda, choose one of the following:<ul> <li>Anaconda is popular for its user-friendly GUI and pre-installed packages, but it's quite large (4.4GB), slow to update, cumbersome, and encourages bad practices \u2014 I'd recommend staying away.</li> <li><code>miniconda</code> is a smaller, more minimalistic version of Conda which only includes the essentials \u2014 this is a good options for beginners who want to minimize fuss while adhering to good practices.</li> <li><code>mamba</code> is a third-party drop-in replacement for <code>conda</code> which is much more fast/efficient \u2014 I recommend this if you're comfortable with the command line and want the best possible experience.</li> </ul> </li> <li><code>poetry</code>/<code>pdm</code>/<code>flit</code>/<code>hatch</code>/<code>rye</code> \u2014 Newer tools for Python developers which aim to simplify the process of managing dependencies and packaging projects.</li> <li><code>uv</code> \u2014 A new tool which aims to unify the best features of all the above tools into a single, easy-to-use interface.</li> </ul> <p> </p>"},{"location":"tutorials/getting_started/install_python/#3-my-recommendation","title":"[3] My Recommendation","text":"<p>I started with <code>venv</code>, moved to <code>mamba</code> for about four years, and finally settled on <code>uv</code> by Astral since mid-2024. Although it's still under rapid development (it was first released in February 2024 as a drop-in <code>pip</code> replacement, and only began supporting more advanced features with v0.3.0 in August 2024), it's gained a ton of traction in the Python community and many have completely switched over(1). It's now my go-to recommendation for beginners and experienced users alike, whether you're doing simple scripting, data analysis, package development, or anything else.</p> <ol> <li>see broader discussions/testimonials here</li> </ol> <p>RedPlanet was fully developed and published with <code>uv</code>, it's been a joy to work with :)</p> <p> </p>"},{"location":"tutorials/getting_started/install_python/#4-editors","title":"[4] Editors","text":"<p>TODO: Flesh this section out more. A quick but sufficient explanation is:</p> <ul> <li>\"Jupyter Notebook\" and \"Jupyter Lab\" are two decent editors which require minimal configuration.</li> <li>Personally, I'd highly recommend using Jupyter within VSCode (this link provides an amazing overview/explanation/tutorial). Bonus points for using VSCodium, which is functionally identical to VSCode but free/open-source and without the telemetry/tracking.</li> </ul>"},{"location":"tutorials/getting_started/online_demo/","title":"Online Demo","text":"<p>Whether you're a beginner who's never installed Python before or an advanced user who'd like a demo before installing, Google Colab is a great way to try all the features of RedPlanet completely in your browser without installing anything! Just open the link above.</p>"},{"location":"usage/","title":"Full Index of API Reference","text":"<p>This page gives an overview of all public RedPlanet objects, functions and methods.</p> <p>All of this information is also accessible with Python's built-in <code>help</code> function \u2014 for example, try running <code>help(redplanet.Craters.get)</code> in your shell/notebook.</p>"},{"location":"usage/#1-user-config","title":"[1] User Config","text":"<p>Configure where datasets will be downloaded and how file integrity is verified.</p> <ul> <li>get_dirpath_datacache()</li> <li>set_dirpath_datacache(...)</li> <li>get_max_size_to_calculate_hash_GiB()</li> <li>set_max_size_to_calculate_hash_GiB(...)</li> <li>get_enable_stream_hash_check()</li> <li>set_enable_stream_hash_check(...)</li> </ul>"},{"location":"usage/#2-datasets","title":"[2] Datasets","text":"<p>Loading/accessing datasets in a standardized way.</p> <ul> <li>Craters:<ul> <li>get(...)</li> </ul> </li> <li>Crust:<ul> <li>Topography / DEM:<ul> <li>load(...)</li> <li>get(...)</li> <li>get_metadata()</li> <li>get_dataset()</li> </ul> </li> <li>Dichotomy:<ul> <li>get_coords()</li> <li>is_above(...)</li> </ul> </li> <li>Mohorovi\u010di\u0107 Discontinuity / Crustal Thickness:<ul> <li>get_registry()</li> <li>load(...)</li> <li>get(...)</li> <li>get_metadata()</li> <li>get_dataset()</li> </ul> </li> <li>Bouguer Anomaly:<ul> <li>load(...)</li> <li>get(...)</li> <li>get_metadata()</li> <li>get_dataset()</li> </ul> </li> </ul> </li> <li>Gamma-Ray Spectrometer (GRS):<ul> <li>get(...)</li> <li>get_metadata()</li> <li>get_dataset()</li> </ul> </li> <li>Magnetic Field:<ul> <li>Spherical Harmonic Models:<ul> <li>load(...)</li> <li>get(...)</li> <li>get_metadata()</li> <li>get_dataset()</li> </ul> </li> <li>Magnetic Source Depths:<ul> <li>get_dataset(...)</li> <li>get_nearest(...)</li> <li>get_grid(...)</li> </ul> </li> </ul> </li> </ul> <p>All <code>load(...)</code> functions will check if a dataset file already exists in your cache directory. If found, it verifies the hash to ensure it wasn't modified; if not found, it will download and verify the file. For convenience, we provide <code>prefetch()</code> to download a few key datasets all at once.</p> <p>To plot any raster (i.e. regularly gridded) data with many convenience features including hillshade underlay, use:</p> <ul> <li>plot(...)</li> </ul> <p> </p>"},{"location":"usage/#3-analysis","title":"[3] Analysis","text":"<p>Advanced dataset operations/calculations and other tools.</p> <ul> <li>Radial Profile:<ul> <li>get_concentric_ring_coords(...)</li> <li>get_profile(...)</li> </ul> </li> <li>Impact Demagnetization:<ul> <li>compute_pressure(...)</li> </ul> </li> </ul>"},{"location":"usage/#4-helper-functions","title":"[4] Helper Functions","text":"<p>Miscellaneous functions used internally.</p> <ul> <li>Coordinates:<ul> <li>_plon2slon(...)</li> <li>_slon2plon(...)</li> </ul> </li> <li>Geodesy:<ul> <li>get_distance(...)</li> <li>move_forward(...)</li> <li>make_circle(...)</li> </ul> </li> <li>Misc:<ul> <li>timer(...)</li> <li>prefetch()</li> </ul> </li> </ul>"},{"location":"usage/analysis/impact_demag/compute_pressure/","title":"compute_pressure(...)","text":""},{"location":"usage/analysis/impact_demag/compute_pressure/#redplanet.analysis.impact_demag.compute_pressure","title":"redplanet.analysis.impact_demag.compute_pressure","text":"<pre><code>compute_pressure(\n    diameter_km: float,\n    x_vals_km: float | numpy.ndarray,\n    y_vals_km: float | numpy.ndarray,\n    v_proj_km_s: float = 10,\n    rho_proj_kg_m3: float = 2900,\n    rho_crust_kg_m3: float = 2900,\n    transition_diameter_km: float = 7,\n    compressibility: float = 1.5,\n    bulk_sound_speed_km_s: float = 3.5,\n    pressure_decay_const: float = 1.87,\n    return_params: bool = False,\n) -&gt; numpy.ndarray | tuple[numpy.ndarray, dict]\n</code></pre> <p>Compute the maximum subsurface shock pressures from an impact using the Rankine-Hugoniot relations.</p> <p>Parameters:</p> Name Type Description Default <code>diameter_km</code> <code>float</code> <p>Observed crater diameter in kilometers. This is the primary crater-dependent input.</p> required <code>x_vals_km</code> <code>float | np.ndarray</code> <p>Horizontal (parallel to surface) point(s) in kilometers where the pressure is to be computed.</p> required <code>y_vals_km</code> <code>float | np.ndarray</code> <p>Vertical (perpendicular to surface) point(s) in kilometers where the pressure is to be computed.</p> required <code>v_proj_km_s</code> <code>float</code> <p>Projectile velocity in kilometers per second. Default is 10 km/s.</p> <code>10</code> <code>rho_proj_kg_m3</code> <code>float</code> <p>Projectile density in kilograms per cubic meter. Default is 2900 kg/m^3.</p> <code>2900</code> <code>rho_crust_kg_m3</code> <code>float</code> <p>Target (crust) density in kilograms per cubic meter. Default is 2900 kg/m^3.</p> <code>2900</code> <code>transition_diameter_km</code> <code>float</code> <p>Transition diameter (in kilometers) from simple to complex crater morphology. Default is 7 km.</p> <code>7</code> <code>compressibility</code> <code>float</code> <p>Compressibility coefficient of the target material (dimensionless). Default is 1.5.</p> <code>1.5</code> <code>bulk_sound_speed_km_s</code> <code>float</code> <p>Bulk sound speed in the target material in kilometers per second. Default is 3.5 km/s.</p> <code>3.5</code> <code>pressure_decay_const</code> <code>float</code> <p>Exponential decay constant for the pressure (or particle velocity) outside the isobaric core. Default is 1.87.</p> <code>1.87</code> <code>return_params</code> <code>bool</code> <p>If True, the function will also return a dictionary of intermediate parameters. Default is False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>P_eff</code> <code>np.ndarray</code> <p>Shock pressures in GPa at the specified point(s), with shape <code>(len(y_vals_km), len(x_vals_km))</code>.</p> <code>params</code> <code>dict</code> <p>Only returned if <code>return_params</code> is True.</p> <p>A dictionary with the following keys:</p> <ul> <li><code>v_proj_km_s</code> \u2014 Projectile velocity (km/s).</li> <li><code>rho_proj_kg_m3</code> \u2014 Projectile density (kg/m^3).</li> <li><code>rho_crust_kg_m3</code> \u2014 Crust density (kg/m^3).</li> <li><code>transition_diameter_km</code> \u2014 Transition crater diameter (km).</li> <li><code>compressibility</code> \u2014 Compressibility coefficient.</li> <li><code>bulk_sound_speed_km_s</code> \u2014 Bulk sound speed (km/s).</li> <li><code>pressure_decay_const</code> \u2014 Pressure decay exponent.</li> <li><code>transient_diameter_km</code> \u2014 Transient crater diameter (km).</li> <li><code>E_proj_J</code> \u2014 Projectile kinetic energy (Joules).</li> <li><code>proj_radius_km</code> \u2014 Projectile radius (km).</li> <li><code>isobaric_radius_km</code> \u2014 Isobaric core radius (km).</li> <li><code>u_ic_km_s</code> \u2014 Particle velocity in the isobaric core (km/s).</li> <li><code>rise_time</code> \u2014 Shock pressure rise time (s).</li> </ul> Notes <p>For a full explanation/derivation of methods and equations, see \"Supplemental &gt; Impact Demagnetization\" in the RedPlanet documentation website.</p> Source code in <code>src/redplanet/analysis/impact_demag.py</code> <pre><code>def compute_pressure(\n    diameter_km            : float,\n    x_vals_km              : float | np.ndarray,\n    y_vals_km              : float | np.ndarray,\n    v_proj_km_s            : float = 10,\n    rho_proj_kg_m3         : float = 2900,\n    rho_crust_kg_m3        : float = 2900,\n    transition_diameter_km : float = 7,\n    compressibility        : float = 1.5,\n    bulk_sound_speed_km_s  : float = 3.5,\n    pressure_decay_const   : float = 1.87,\n    return_params          : bool  = False,\n) -&gt; np.ndarray | tuple[np.ndarray, dict]:\n    \"\"\"\n    Compute the maximum subsurface shock pressures from an impact using the Rankine-Hugoniot relations.\n\n\n    Parameters\n    ----------\n    diameter_km : float\n        Observed crater diameter in kilometers. This is the primary crater-dependent input.\n    x_vals_km : float | np.ndarray\n        Horizontal (parallel to surface) point(s) in kilometers where the pressure is to be computed.\n    y_vals_km : float | np.ndarray\n        Vertical (perpendicular to surface) point(s) in kilometers where the pressure is to be computed.\n    v_proj_km_s : float, optional\n        Projectile velocity in kilometers per second. Default is 10 km/s.\n    rho_proj_kg_m3 : float, optional\n        Projectile density in kilograms per cubic meter. Default is 2900 kg/m^3.\n    rho_crust_kg_m3 : float, optional\n        Target (crust) density in kilograms per cubic meter. Default is 2900 kg/m^3.\n    transition_diameter_km : float, optional\n        Transition diameter (in kilometers) from simple to complex crater morphology. Default is 7 km.\n    compressibility : float, optional\n        Compressibility coefficient of the target material (dimensionless). Default is 1.5.\n    bulk_sound_speed_km_s : float, optional\n        Bulk sound speed in the target material in kilometers per second. Default is 3.5 km/s.\n    pressure_decay_const : float, optional\n        Exponential decay constant for the pressure (or particle velocity) outside the isobaric core. Default is 1.87.\n    return_params : bool, optional\n        If True, the function will also return a dictionary of intermediate parameters. Default is False.\n\n\n    Returns\n    -------\n    P_eff : np.ndarray\n        Shock pressures in GPa at the specified point(s), with shape `(len(y_vals_km), len(x_vals_km))`.\n\n    params : dict\n        Only returned if `return_params` is True.\n\n        A dictionary with the following keys:\n\n        - `v_proj_km_s` \u2014 Projectile velocity (km/s).\n        - `rho_proj_kg_m3` \u2014 Projectile density (kg/m^3).\n        - `rho_crust_kg_m3` \u2014 Crust density (kg/m^3).\n        - `transition_diameter_km` \u2014 Transition crater diameter (km).\n        - `compressibility` \u2014 Compressibility coefficient.\n        - `bulk_sound_speed_km_s` \u2014 Bulk sound speed (km/s).\n        - `pressure_decay_const` \u2014 Pressure decay exponent.\n        - `transient_diameter_km` \u2014 Transient crater diameter (km).\n        - `E_proj_J` \u2014 Projectile kinetic energy (Joules).\n        - `proj_radius_km` \u2014 Projectile radius (km).\n        - `isobaric_radius_km` \u2014 Isobaric core radius (km).\n        - `u_ic_km_s` \u2014 Particle velocity in the isobaric core (km/s).\n        - `rise_time` \u2014 Shock pressure rise time (s).\n\n\n    Notes\n    -----\n    For a full explanation/derivation of methods and equations, see \"Supplemental &gt; Impact Demagnetization\" in the RedPlanet documentation website.\n    \"\"\"\n\n    ## Convert inputs to SI and shorthands\n    D_o       = diameter_km * 1e3\n    x_1d      = x_vals_km * 1e3\n    y_1d      = y_vals_km * 1e3\n    v_proj    = v_proj_km_s * 1e3\n    rho_proj  = rho_proj_kg_m3\n    rho_crust = rho_crust_kg_m3\n    D_star    = transition_diameter_km * 1e3\n    C         = bulk_sound_speed_km_s * 1e3\n    S         = compressibility\n    n         = pressure_decay_const\n    g         = 3.72076\n    ## EVERYTHING FROM HERE FORWARD IS SI\n\n    D_tr = 0.7576 * D_o**0.921 * D_star**0.079\n\n    E_proj = ((1/0.2212) * D_tr * v_proj**0.09 * g**0.22)**(1/0.26)\n    r_proj = ((3 * E_proj) / (2 * np.pi * rho_proj * v_proj**2))**(1/3)\n\n    R_ic = r_proj * 0.7\n    u_ic = 0.5 * v_proj\n    tau_rise = r_proj / v_proj\n\n    x_2d, y_2d = np.meshgrid(x_1d, y_1d)  ## X and Y are each 2D arrays, now calculations can be better broadcasted/vectorized\n\n    R_dir = np.sqrt(x_2d**2 + (y_2d - R_ic)**2)\n    R_ref = np.sqrt(x_2d**2 + (y_2d + R_ic)**2)\n    delta_t = (R_ref - R_dir) / C\n\n    def calc_u_p(r):\n        return np.where(\n            r &lt;= R_ic,\n            u_ic,\n            u_ic*(r/R_ic)**(-n)\n        )\n\n    def calc_P_direct(r):\n        u_p = calc_u_p(r)\n        return rho_crust * u_p * (C + S*u_p)\n\n    P_direct    = calc_P_direct(R_dir)\n    P_reflected = calc_P_direct(R_ref)\n\n    P_eff = np.where(\n        delta_t &gt;= tau_rise,\n        P_direct,\n        P_direct - P_reflected*(1 - delta_t/tau_rise)\n    )\n\n    P_eff = P_eff * 1e-9\n    P_eff = np.squeeze(P_eff)\n\n    if return_params:\n        return (\n            P_eff,\n            {\n                'v_proj_km_s'            : v_proj_km_s,\n                'rho_proj_kg_m3'         : rho_proj_kg_m3,\n                'rho_crust_kg_m3'        : rho_crust_kg_m3,\n                'transition_diameter_km' : transition_diameter_km,\n                'compressibility'        : compressibility,\n                'bulk_sound_speed_km_s'  : bulk_sound_speed_km_s,\n                'pressure_decay_const'   : pressure_decay_const,\n                'transient_diameter_km'  : D_tr * 1e-3,\n                'E_proj_J'               : E_proj,\n                'proj_radius_km'         : r_proj * 1e-3,\n                'isobaric_radius_km'     : R_ic * 1e-3,\n                'u_ic_km_s'              : u_ic * 1e-3,\n                'rise_time'              : tau_rise,\n            }\n        )\n    return P_eff\n</code></pre>"},{"location":"usage/analysis/radial_profile/get_concentric_ring_coords/","title":"get_concentric_ring_coords(...)","text":""},{"location":"usage/analysis/radial_profile/get_concentric_ring_coords/#redplanet.analysis.radial_profile.get_concentric_ring_coords","title":"redplanet.analysis.radial_profile.get_concentric_ring_coords","text":"<pre><code>get_concentric_ring_coords(\n    lon: float,\n    lat: float,\n    radius_km: float,\n    dist_btwn_rings_km: float = Ellipsis,\n    num_rings: int = None,\n    dist_btwn_points_km: float = 5,\n) -&gt; tuple[numpy.ndarray, tuple[numpy.ndarray]]\n</code></pre> <p>Generate concentric ring coordinates around a central point.</p> <p>This function computes the radii for a series of concentric rings centered at the specified location and then generates (longitude, latitude) coordinates for equally spaced points along each ring. The rings can be defined by either a fixed distance between rings or by specifying the total number of rings to generate.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>float</code> <p>Longitude coordinate of the center of the circle, in range [-180, 360].</p> required <code>lat</code> <code>float</code> <p>Latitude coordinate of the center of the circle, in range [-90, 90].</p> required <code>radius_km</code> <code>float</code> <p>Radius (in kilometers) of the largest/outermost ring.</p> required <code>dist_btwn_rings_km</code> <code>float</code> <p>Distance (in kilometers) between consecutive rings. You can't provide both this and <code>num_rings</code>. Default is 5 km.</p> <code>Ellipsis</code> <code>num_rings</code> <code>int</code> <p>Total number of rings to generate. You can't provide both this and <code>dist_btwn_rings_km</code>. Default is None.</p> <code>None</code> <code>dist_btwn_points_km</code> <code>float</code> <p>Desired spacing (in kilometers) between adjacent points on each ring. Default is 5.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>ring_radius_km__per_ring</code> <code>np.ndarray</code> <p>Ring radii (in kilometers) for each ring.</p> <code>ring_coords__per_ring</code> <code>tuple[np.ndarray]</code> <p>A tuple of 2D numpy arrays, each containing the (longitude, latitude) coordinates of points on the corresponding ring (shape is <code>(num_points,2)</code>).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If either both or neither of <code>dist_btwn_rings_km</code> and <code>num_rings</code> are specified.</p> Notes <p>For examples, see \"Tutorials &amp; Guides\" on the RedPlanet documentation website.</p> Source code in <code>src/redplanet/analysis/radial_profile.py</code> <pre><code>def get_concentric_ring_coords(\n    lon                 : float,\n    lat                 : float,\n    radius_km           : float,\n    dist_btwn_rings_km  : float = ...,\n    num_rings           : int   = None,\n    dist_btwn_points_km : float = 5,\n) -&gt; tuple[ np.ndarray, tuple[np.ndarray] ]:\n    \"\"\"\n    Generate concentric ring coordinates around a central point.\n\n    This function computes the radii for a series of concentric rings centered at the specified location and then generates (longitude, latitude) coordinates for equally spaced points along each ring. The rings can be defined by either a fixed distance between rings or by specifying the total number of rings to generate.\n\n    Parameters\n    ----------\n    lon : float\n        Longitude coordinate of the center of the circle, in range [-180, 360].\n    lat : float\n        Latitude coordinate of the center of the circle, in range [-90, 90].\n    radius_km : float\n        Radius (in kilometers) of the largest/outermost ring.\n    dist_btwn_rings_km : float, optional\n        Distance (in kilometers) between consecutive rings. You can't provide both this and `num_rings`. Default is 5 km.\n    num_rings : int, optional\n        Total number of rings to generate. You can't provide both this and `dist_btwn_rings_km`. Default is None.\n    dist_btwn_points_km : float, optional\n        Desired spacing (in kilometers) between adjacent points on each ring. Default is 5.\n\n    Returns\n    -------\n    ring_radius_km__per_ring : np.ndarray\n        Ring radii (in kilometers) for each ring.\n    ring_coords__per_ring : tuple[np.ndarray]\n        A tuple of 2D numpy arrays, each containing the (longitude, latitude) coordinates of points on the corresponding ring (shape is `(num_points,2)`).\n\n    Raises\n    ------\n    ValueError\n        If either both or neither of `dist_btwn_rings_km` and `num_rings` are specified.\n\n    Notes\n    -----\n    For examples, see [\"Tutorials &amp; Guides\"](/redplanet/tutorials/){target=\"_blank\"} on the RedPlanet documentation website.\n    \"\"\"\n\n    ## Input validation and defaults \u2014 after this, we're guaranteed one of `dist_btwn_rings_km` or `num_rings` will be a float and the other will be None.\n    if (dist_btwn_rings_km is not ...) and (num_rings is not None):\n        raise ValueError('Cannot provide both `dist_btwn_rings_km` and `num_rings` \u2014 provide only one or neither.')\n\n    if num_rings:\n        dist_btwn_rings_km = None\n    else:\n        dist_btwn_rings_km = 5\n\n    ## Get radii for a series of concentric rings, starting at the center and going up to a distance of `radius_km`.\n    if dist_btwn_rings_km:\n        ring_radius_km__per_ring = np.arange(0, radius_km, dist_btwn_rings_km)\n    else:\n        ring_radius_km__per_ring = np.linspace(0, radius_km, num_rings)\n\n    ## Calculate the number of points that can fit in each ring such that each point is `dist_btwn_points_km` away from its neighbors.\n    ## Given a circle with radius `r`, the number of points you could fit around the circumference (`2*pi*r`) such that every point is distance `x` from its neighbors is given by `2*pi*r/x`.\n    num_points__per_ring = np.ceil(2 * np.pi * ring_radius_km__per_ring / dist_btwn_points_km).astype(int)\n    ## note: we're using ceil here to ensure atleast 1 point per ring :)    (i think???)\n\n    ## Enforce a minimum number of points per ring\n    min_num_points = 10\n    num_points__per_ring[num_points__per_ring &lt; min_num_points] = min_num_points\n\n    ## Generate (lon,lat) coordinates for each point on each ring.\n    ring_coords__per_ring = []\n    for (ring_radius_km, num_points) in zip(ring_radius_km__per_ring, num_points__per_ring):\n        ## Generate the (lon,lat) coordinates of `num_points` points around the circle of radius `ring_radius_km`.\n        ring_coords = geodesy.make_circle(\n            lon       = lon,\n            lat       = lat,\n            radius    = ring_radius_km * 1e3,\n            n_samples = num_points,\n            endpoint  = False,\n        )\n        ring_coords__per_ring.append(ring_coords)\n\n    return (\n        ring_radius_km__per_ring,\n        tuple(ring_coords__per_ring)\n    )\n</code></pre>"},{"location":"usage/analysis/radial_profile/get_profile/","title":"get_profile(...)","text":""},{"location":"usage/analysis/radial_profile/get_profile/#redplanet.analysis.radial_profile.get_profile","title":"redplanet.analysis.radial_profile.get_profile","text":"<pre><code>get_profile(\n    ring_coords__per_ring: tuple[numpy.ndarray],\n    accessor: collections.abc.Callable[\n        [float, float], float\n    ],\n    return_stats: bool = False,\n) -&gt; (\n    numpy.ndarray\n    | tuple[\n        numpy.ndarray, numpy.ndarray, tuple[numpy.ndarray]\n    ]\n)\n</code></pre> <p>Compute a radial profile using data extracted from concentric rings.</p> <p>This function computes a one-dimensional radial profile by applying an accessor function to a set of coordinates along each ring. For each ring, it averages the values returned by the accessor function. Optionally, the function can also return additional statistical information.</p> <p>Parameters:</p> Name Type Description Default <code>ring_coords__per_ring</code> <code>tuple[np.ndarray]</code> <p>A tuple where each element is a numpy array containing (longitude, latitude) coordinate pairs for a ring. This corresponds to the second output of <code>get_concentric_ring_coords</code>.</p> required <code>accessor</code> <code>Callable[[float, float], float]</code> <p>A function that accepts two arguments (longitude and latitude), then returns a numerical value corresponding to a data point at those coordinates. See Notes for more information.</p> required <code>return_stats</code> <code>bool</code> <p>If True, the function returns additional statistical data (standard deviation and raw values for each ring) along with the averaged values. Default is False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>avg_vals__per_ring</code> <code>np.ndarray</code> <p>Averaged values per ring (starting with the smallest).</p> <code>sigma__per_ring</code> <code>np.ndarray</code> <p>Only returned if <code>return_stats</code> is True.</p> <p>Standard deviations (sigma) per ring.</p> <code>vals__per_ring</code> <code>tuple[np.ndarray]</code> <p>Only returned if <code>return_stats</code> is True.</p> <p>A tuple of 1D numpy arrays, each containing the data values extracted from each ring (shape is <code>(num_points,)</code>).</p> Notes <p>The input for the <code>accessor</code> parameter must be a function, which might be confusing. Here are two examples (assume datasets have already been loaded):</p> <ul> <li>Example 1: For functions which only take longitude and latitude as arguments (e.g., topography), you can simply pass <code>accessor = redplanet.Crust.topo.get</code>.</li> <li>Example 2: For functions which require additional arguments (e.g., vector components of the magnetic field or custom calculations), you should define a separate function that will only require longitude and latitude as arguments. There are two ways to do this:<ul> <li>Directly supply a lambda function like <code>accessor = lambda lon, lat: redplanet.Mag.sh.get(lon, lat, quantity='radial')</code> \u2014 this is ideal for simple one-line accessors.</li> <li>Define a function separately like <code>def get_value(lon, lat): return redplanet.Mag.sh.get(lon, lat, quantity='radial')</code>, and then pass <code>accessor = get_value</code> \u2014 this is ideal when your implementation of the <code>get_value</code> function involves multiple steps, e.g. querying multiple datasets, performing calculations, conditional/loop blocks, etc.</li> </ul> </li> </ul> Source code in <code>src/redplanet/analysis/radial_profile.py</code> <pre><code>def get_profile(\n    ring_coords__per_ring : tuple[np.ndarray],\n    accessor              : Callable[[float, float], float],\n    return_stats          : bool = False,\n) -&gt; np.ndarray | tuple[ np.ndarray, np.ndarray, tuple[np.ndarray] ]:\n    \"\"\"\n    Compute a radial profile using data extracted from concentric rings.\n\n    This function computes a one-dimensional radial profile by applying an accessor function to a set of coordinates along each ring. For each ring, it averages the values returned by the accessor function. Optionally, the function can also return additional statistical information.\n\n\n    Parameters\n    ----------\n    ring_coords__per_ring : tuple[np.ndarray]\n        A tuple where each element is a numpy array containing (longitude, latitude) coordinate pairs for a ring. This corresponds to the second output of `get_concentric_ring_coords`.\n    accessor : Callable[[float, float], float]\n        A function that accepts two arguments (longitude and latitude), then returns a numerical value corresponding to a data point at those coordinates. See Notes for more information.\n    return_stats : bool, optional\n        If True, the function returns additional statistical data (standard deviation and raw values for each ring) along with the averaged values. Default is False.\n\n\n    Returns\n    -------\n    avg_vals__per_ring : np.ndarray\n        Averaged values per ring (starting with the smallest).\n\n    sigma__per_ring : np.ndarray\n        Only returned if `return_stats` is True.\n\n        Standard deviations (sigma) per ring.\n\n    vals__per_ring : tuple[np.ndarray]\n        Only returned if `return_stats` is True.\n\n        A tuple of 1D numpy arrays, each containing the data values extracted from each ring (shape is `(num_points,)`).\n\n    Notes\n    -----\n    The input for the `accessor` parameter must be a function, which might be confusing. Here are two examples (assume datasets have already been loaded):\n\n    - Example 1: For functions which only take longitude and latitude as arguments (e.g., topography), you can simply pass `accessor = redplanet.Crust.topo.get`.\n    - Example 2: For functions which require additional arguments (e.g., vector components of the magnetic field or custom calculations), you should define a separate function that will only require longitude and latitude as arguments. There are two ways to do this:\n        - Directly supply a lambda function like `accessor = lambda lon, lat: redplanet.Mag.sh.get(lon, lat, quantity='radial')` \u2014 this is ideal for simple one-line accessors.\n        - Define a function separately like `def get_value(lon, lat): return redplanet.Mag.sh.get(lon, lat, quantity='radial')`, and then pass `accessor = get_value` \u2014 this is ideal when your implementation of the `get_value` function involves multiple steps, e.g. querying multiple datasets, performing calculations, conditional/loop blocks, etc.\n    \"\"\"\n\n    vals__per_ring = []\n    for ring_coords in ring_coords__per_ring:\n        vals = []\n        for (lon, lat) in ring_coords:\n            vals.append(accessor(lon, lat))\n        vals = np.array(vals)\n        vals__per_ring.append(vals)\n\n    avg_vals__per_ring = np.array([np.mean(vals) for vals in vals__per_ring])\n\n    if not return_stats:\n        return avg_vals__per_ring\n\n    sigma__per_ring = np.array([np.std(vals) for vals in vals__per_ring])\n\n    return (\n        avg_vals__per_ring,\n        sigma__per_ring,\n        tuple(vals__per_ring),\n    )\n</code></pre>"},{"location":"usage/datasets/Craters/get/","title":"get(...)","text":""},{"location":"usage/datasets/Craters/get/#redplanet.Craters.get","title":"redplanet.Craters.get","text":"<pre><code>get(\n    crater_id: None | str | list[str] = None,\n    name: None | str | list[str] = None,\n    lon: None | tuple[float, float] = None,\n    lat: None | tuple[float, float] = None,\n    diameter: None | tuple[float, float] = None,\n    has_age: None | bool = None,\n    as_df: bool = False,\n) -&gt; list[dict] | pandas.core.frame.DataFrame\n</code></pre> <p>Filter/query a dataset of craters &gt;50km diameter, with ages/names when available. Calling this with no arguments will return the full dataset.</p> <p>We create a custom dataset (0.28 MiB) which unifies the following:</p> <ol> <li>Global database of Martian impact craters (Robbins &amp; Hynek, 2012).</li> <li>Crater ages from both Hartmann and Neukum isochron methods (Robbins et al., 2013).</li> <li>IAU-approved crater nomenclature (USGS Astrogeology Science Center, 2024}).</li> </ol> <p>For more information and code to reproduce the dataset, see https://github.com/Humboldt-Penguin/redplanet/tree/main/datasets/Craters -- TODO: I'll eventually have a section on my website to describe datasets and how we modified them, add a link to that here.</p> <p>Parameters:</p> Name Type Description Default <code>crater_id</code> <code>None | str | list[str]</code> <p>Unique crater identifier formatted ##-######, where the first two numbers indicate the Mars subquad and the last six number the craters in that subquad from largest to smallest diameter.</p> <code>None</code> <code>name</code> <code>None | str | list[str]</code> <p>Crater name according to official IAU nomenclature (as of 2024-11-26).</p> <code>None</code> <code>lon</code> <code>None | tuple[float, float]</code> <p>Filter craters whose center falls within this range of longitudes.</p> <p>The given range must be a subset of either [-180,180] or [0,360] -- e.g. <code>lon=[-170,350]</code> is not allowed (it doesn't make sense).</p> <code>None</code> <code>lat</code> <code>None | tuple[float, float]</code> <p>Filter craters whose center falls within this range of latitudes.</p> <code>None</code> <code>diameter</code> <code>None | tuple[float, float]</code> <p>Filter craters whose diameter falls within this range, in kilometers.</p> <code>None</code> <code>has_age</code> <code>None | bool</code> <p>If True, only return craters with both Hartmann/Neukum isochron ages available. Default is False.</p> <code>None</code> <code>as_df</code> <code>bool</code> <p>If True, return a pandas DataFrame. Default is False, which returns a list of dictionaries.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict] | pd.DataFrame</code> <p>Filtered list of craters with keys/columns:</p> <ul> <li><code>id</code> : str<ul> <li>Unique crater identifier formatted ##-######, where the first two numbers indicate the Mars subquad and the last six number the craters in that subquad from largest to smallest diameter.</li> </ul> </li> <li><code>name</code> : str<ul> <li>Crater name according to official IAU nomenclature (as of 2024-11-26).</li> </ul> </li> <li><code>lat</code> : float<ul> <li>Latitude of the crater center.</li> </ul> </li> <li><code>lon</code> : float<ul> <li>Longitude of the crater center, in range [-180,180].</li> </ul> </li> <li>'plon' : float<ul> <li>Longitude of the crater center, in range [0,360].</li> </ul> </li> <li><code>diam</code> : float<ul> <li>Diameter of the crater, in km.</li> </ul> </li> <li><code>['diam_sd', 'diam_elli_major', 'diam_elli_minor', 'diam_elli_angle', 'diam_elli_major_sd', 'diam_elli_minor_sd']</code> : float<ul> <li>For more info, see Appendix A of Robbins and Hynek (2012).</li> </ul> </li> <li><code>['N_H(10)', 'N_N(10)', 'N_H(25)', 'N_N(25)', 'N_H(50)', 'N_N(50)', 'Hartmann Isochron Age', 'Neukum Isochron Age', 'Hartmann Turn-Off Diameter', 'Neukum Turn-Off Diameter']</code> : None | list[float, float, float]<ul> <li>When available, the ages are given in a list where the first value is the estimated age and second/third are uncertainties (they will always be negative/positive respectively). All values are in billions of years (aka \"giga-annums\"/\"Ga\").</li> <li>For more info, see Supplementary Table 3 of Robbins et al. (2013).</li> </ul> </li> </ul> References <ol> <li>Robbins, S. J., &amp; Hynek, B. M. (2012). A new global database of Mars impact craters \u22651 km: 1. Database creation, properties, and parameters. Journal of Geophysical Research: Planets, 117(E5). https://doi.org/10.1029/2011JE003966 [Database available at https://craters.sjrdesign.net/]</li> <li>Robbins, S. J., Hynek, B. M., Lillis, R. J., &amp; Bottke, W. F. (2013). Large impact crater histories of Mars: The effect of different model crater age techniques. Icarus, 225(1), 173-184. https://doi.org/10.1016/j.icarus.2013.03.019 [For age data, see Supplementary Table 3]</li> <li>USGS Astrogeology Science Center (2024). Gazetteer of Planetary Nomenclature: Craters on Mars [Dataset]. U.S. Geological Survey. https://planetarynames.wr.usgs.gov/SearchResults?Target=20_Mars&amp;Feature%20Type=9_Crater,%20craters [Accessed 2024-11-26]</li> </ol> Source code in <code>src/redplanet/Craters/getter.py</code> <pre><code>@substitute_docstrings\ndef get(\n    crater_id : None | str | list[str]     = None,\n    name      : None | str | list[str]     = None,\n    lon       : None | tuple[float, float] = None,\n    lat       : None | tuple[float, float] = None,\n    diameter  : None | tuple[float, float] = None,\n    has_age   : None | bool                = None,\n    as_df     : bool                       = False,\n) -&gt; list[dict] | pd.DataFrame:\n    \"\"\"\n    Filter/query a dataset of craters &gt;50km diameter, with ages/names when available. Calling this with no arguments will return the full dataset.\n\n    We create a custom dataset (0.28 MiB) which unifies the following:\n\n    1. Global database of Martian impact craters ({@Robbins2012_crater_db.p}).\n    2. Crater ages from both Hartmann and Neukum isochron methods ({@Robbins2013_crater_ages.p}).\n    3. IAU-approved crater nomenclature ({@IAU_crater_names.p}}).\n\n    For more information and code to reproduce the dataset, see &lt;https://github.com/Humboldt-Penguin/redplanet/tree/main/datasets/Craters&gt;{target=\"_blank\"} -- TODO: I'll eventually have a section on my website to describe datasets and how we modified them, add a link to that here.\n\n    Parameters\n    ----------\n    crater_id : None | str | list[str], optional\n        Unique crater identifier formatted ##-######, where the first two numbers indicate the Mars subquad and the last six number the craters in that subquad from largest to smallest diameter.\n    name : None | str | list[str], optional\n        Crater name according to official IAU nomenclature (as of 2024-11-26).\n    lon : None | tuple[float, float], optional\n        Filter craters whose center falls within this range of longitudes.\n\n        The given range must be a subset of either [-180,180] or [0,360] -- e.g. `lon=[-170,350]` is not allowed (it doesn't make sense).\n    lat : None | tuple[float, float], optional\n        Filter craters whose center falls within this range of latitudes.\n    diameter : None | tuple[float, float], optional\n        Filter craters whose diameter falls within this range, in kilometers.\n    has_age : None | bool, optional\n        If True, only return craters with both Hartmann/Neukum isochron ages available. Default is False.\n    as_df : bool, optional\n        If True, return a pandas DataFrame. Default is False, which returns a list of dictionaries.\n\n    Returns\n    -------\n    list[dict] | pd.DataFrame\n        Filtered list of craters with keys/columns:\n\n        - `id` : str\n            - Unique crater identifier formatted ##-######, where the first two numbers indicate the Mars subquad and the last six number the craters in that subquad from largest to smallest diameter.\n        - `name` : str\n            - Crater name according to official IAU nomenclature (as of 2024-11-26).\n        - `lat` : float\n            - Latitude of the crater center.\n        - `lon` : float\n            - Longitude of the crater center, in range [-180,180].\n        - 'plon' : float\n            - Longitude of the crater center, in range [0,360].\n        - `diam` : float\n            - Diameter of the crater, in km.\n        - `['diam_sd', 'diam_elli_major', 'diam_elli_minor', 'diam_elli_angle', 'diam_elli_major_sd', 'diam_elli_minor_sd']` : float\n            - For more info, see Appendix A of {@Robbins2012_crater_db.n}.\n        - `['N_H(10)', 'N_N(10)', 'N_H(25)', 'N_N(25)', 'N_H(50)', 'N_N(50)', 'Hartmann Isochron Age', 'Neukum Isochron Age', 'Hartmann Turn-Off Diameter', 'Neukum Turn-Off Diameter']` : None | list[float, float, float]\n            - When available, the ages are given in a list where the first value is the estimated age and second/third are uncertainties (they will always be negative/positive respectively). All values are in billions of years (aka \"giga-annums\"/\"Ga\").\n            - For more info, see Supplementary Table 3 of {@Robbins2013_crater_ages.n}.\n    \"\"\"\n\n    df = _get_dataset()\n\n    if crater_id:\n        if isinstance(crater_id, str):\n            crater_id = [crater_id]\n        df = df[ df['id'].isin(crater_id) ]\n\n    if name:\n        if isinstance(name, str):\n            name = [name]\n        df = df[ df['name'].isin(name) ]\n        ## TODO: make names insensitive to case and special characters like apostrophes, e.g. \"kovalsky\" == \"Koval'sky\"\n\n\n    if lon:\n        _verify_coords(lon, 0)\n        # lon = _plon2slon(lon)    ## this introduces unexpected/annoying behavior, TODO figure it out eventually lol (or add a plon col to df, and if any input lons are &gt;180 then query that column instead lol)\n        if lon[0] &gt; 180 or lon[1] &gt; 180:\n            df = df[ df['plon'].between(lon[0], lon[1]) ]\n        else:\n            df = df[ df['lon'].between(lon[0], lon[1]) ]\n\n    if lat:\n        _verify_coords(0, lat)\n        df = df[ df['lat'].between(lat[0], lat[1]) ]\n\n\n    if diameter:\n        df = df[ df['diam'].between(diameter[0], diameter[1]) ]\n\n    if has_age:\n        df = df[\n            pd.notna(df['Hartmann Isochron Age']) &amp;\n            pd.notna(df['Neukum Isochron Age'])\n        ]\n\n    if not as_df:\n        df = df.to_dict(orient='records')\n\n    return df\n</code></pre>"},{"location":"usage/datasets/Crust/boug/get/","title":"get(...)","text":""},{"location":"usage/datasets/Crust/boug/get/#redplanet.Crust.boug.get","title":"redplanet.Crust.boug.get","text":"<pre><code>get(\n    lon: float | numpy.ndarray,\n    lat: float | numpy.ndarray,\n    as_xarray: bool = False,\n) -&gt; (\n    float | numpy.ndarray | xarray.core.dataarray.DataArray\n)\n</code></pre> <p>Get Bouguer anomaly values at the specified coordinates. Dataset must be loaded first, see <code>redplanet.Crust.boug.load(...)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>float | np.ndarray</code> <p>Longitude coordinate(s) in range [-180, 360].</p> required <code>lat</code> <code>float | np.ndarray</code> <p>Latitude coordinate(s) in range [-90, 90].</p> required <code>as_xarray</code> <code>bool</code> <p>If True, return the data as an <code>xarray.DataArray</code>. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>float | np.ndarray | xr.DataArray</code> <p>Data values at the the input coordinates. The return type is determined as follows:</p> <ul> <li>float: if both <code>lon</code> and <code>lat</code> are floats.</li> <li>numpy.ndarray (1D): if one of <code>lon</code> or <code>lat</code> is a numpy 1D array and the other is a float.</li> <li>numpy.ndarray (2D): if both <code>lon</code> and <code>lat</code> are numpy 1D arrays. The first dimension of output array corresponds to <code>lat</code> values.</li> <li>xarray.DataArray: see <code>as_xarray</code> parameter (this takes precedence over the above types).</li> </ul> <p>Units are milligals [mGal].</p> Source code in <code>src/redplanet/Crust/boug/getter.py</code> <pre><code>@substitute_docstrings\ndef get(\n    lon       : float | np.ndarray,\n    lat       : float | np.ndarray,\n    as_xarray : bool = False\n) -&gt; float | np.ndarray | xr.DataArray:\n    \"\"\"\n    Get Bouguer anomaly values at the specified coordinates. Dataset must be loaded first, see `redplanet.Crust.boug.load(...)`.\n\n    Parameters\n    ----------\n    {param.lon}\n    {param.lat}\n    {param.as_xarray}\n\n    Returns\n    -------\n    {return.GriddedData}\n\n        Units are milligals [mGal].\n    \"\"\"\n\n    dat_boug = get_dataset()\n\n    return dat_boug.get_values(\n        lon = lon,\n        lat = lat,\n        var = 'boug',\n        as_xarray = as_xarray,\n    )\n</code></pre>"},{"location":"usage/datasets/Crust/boug/get_dataset/","title":"get_dataset()","text":""},{"location":"usage/datasets/Crust/boug/get_dataset/#redplanet.Crust.boug.get_dataset","title":"redplanet.Crust.boug.get_dataset","text":"<pre><code>get_dataset() -&gt; GriddedData\n</code></pre> <p>Get the underlying dataset which is currently loaded.</p> <p>Returns:</p> Type Description <code>GriddedData</code> <p>Instance of RedPlanet's <code>GriddedData</code> class, which stores all coordinate/data/metadata information and accessing/plotting methods.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset has not been loaded yet (see the <code>load</code> function for this module).</p> See Also <p><code>redplanet.helper_functions.GriddedData</code></p> Source code in <code>src/redplanet/Crust/boug/loader.py</code> <pre><code>@substitute_docstrings\ndef get_dataset() -&gt; GriddedData:\n    \"\"\"\n    {fulldoc.get_dataset_GriddedData}\n    \"\"\"\n    if _dat_boug is None:\n        raise ValueError('Bouguer dataset not loaded. Use `redplanet.Crust.boug.load(&lt;model_params&gt;)`.')\n    return _dat_boug\n</code></pre>"},{"location":"usage/datasets/Crust/boug/get_metadata/","title":"get_metadata()","text":""},{"location":"usage/datasets/Crust/boug/get_metadata/#redplanet.Crust.boug.get_metadata","title":"redplanet.Crust.boug.get_metadata","text":"<pre><code>get_metadata() -&gt; dict\n</code></pre> <p>Get metadata for the dataset which is currently loaded.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Contains information about the dataset such as description, units, references, download links, local file path, etc.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset has not been loaded yet (see the <code>load</code> function for this module).</p> Source code in <code>src/redplanet/Crust/boug/loader.py</code> <pre><code>@substitute_docstrings\ndef get_metadata() -&gt; dict:\n    \"\"\"\n    {fulldoc.get_metadata}\n    \"\"\"\n    return dict(get_dataset().metadata)\n</code></pre>"},{"location":"usage/datasets/Crust/boug/load/","title":"load(...)","text":""},{"location":"usage/datasets/Crust/boug/load/#redplanet.Crust.boug.load","title":"redplanet.Crust.boug.load","text":"<pre><code>load(model: str = None) -&gt; None\n</code></pre> <p>Load Bouguer gravity anomaly dataset.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Name of the Bouguer model to load. Options are:</p> <ul> <li><code>'Genova2016'</code> (127 MiB) \u2014 Bouguer gravity anomaly map from Genova (2016), computed from truncated GMM-3 solution (degree 2 to 90) (Genova et al., 2016).</li> </ul> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid model name is provided.</p> References <ol> <li>Genova, A. (2016). Bouguer Gravity Anomaly Map Derived from the NASA GMM-3 Gravity Field [Dataset]. NASA PDS. https://pds-geosciences.wustl.edu/mro/mro-m-rss-5-sdp-v1/mrors_1xxx/data/rsdmap/ [See \"ggmro_120_bouguer_90\" .img and .lbl files]</li> <li>Genova, A., Goossens, S., Lemoine, F. G., Mazarico, E., Neumann, G. A., Smith, D. E., &amp; Zuber, M. T. (2016). Seasonal and static gravity field of Mars from MGS, Mars Odyssey and MRO radio science. Icarus, 272, 228-245. https://doi.org/10.1016/j.icarus.2016.02.050</li> </ol> Source code in <code>src/redplanet/Crust/boug/loader.py</code> <pre><code>@substitute_docstrings\ndef load(model: str = None) -&gt; None:\n    \"\"\"\n    Load Bouguer gravity anomaly dataset.\n\n    Parameters\n    ----------\n    model : str\n        Name of the Bouguer model to load. Options are:\n\n        - `'Genova2016'` (127 MiB) \u2014 Bouguer gravity anomaly map from {@Genova2016_boug_data.n}, computed from truncated GMM-3 solution (degree 2 to 90) ({@Genova2016_boug_paper.p}).\n\n    Raises\n    ------\n    ValueError\n        If an invalid model name is provided.\n    \"\"\"\n\n    ## I expect to add more later, so users should explicitly choose Genova2016 for forward compatibility.\n    info = {\n        'Genova2016': {\n            'shape'          : (2880, 5760),\n            'dtype'          : np.float64,\n            'post-processing': lambda arr: np.flipud(arr),\n            'lon'            : np.linspace(  0, 360, 5760, endpoint=False) + 1 / (2 * 16),\n            'lat'            : np.linspace(-90,  90, 2880, endpoint=False) + 1 / (2 * 16),\n            'metadata': {\n                'description': 'Bouguer gravity anomaly map computed from truncated GMM-3 solution (degree 2 to 90).',\n                'units'      : 'mGal',\n                'links'      : {\n                    'download': 'https://pds-geosciences.wustl.edu/mro/mro-m-rss-5-sdp-v1/mrors_1xxx/data/rsdmap/',\n                    'lbl'     : 'https://pds-geosciences.wustl.edu/mro/mro-m-rss-5-sdp-v1/mrors_1xxx/data/rsdmap/ggmro_120_bouguer_90.lbl',\n                },\n            },\n        },\n    }\n\n    if model not in info:\n        raise ValueError(f\"Invalid Bouguer model: '{model}'. Options are: {list(info.keys())}.\")\n\n\n\n    if model == 'Genova2016':\n\n        fpath = _get_fpath_dataset(model)\n\n        dat = np.memmap(\n            fpath,\n            mode  = 'r',\n            dtype = info[model]['dtype'],\n            shape = info[model]['shape'],\n        )\n        dat = info[model]['post-processing'] (dat)\n\n        metadata = info[model]['metadata']\n        metadata['fpath'] = fpath\n\n        global _dat_boug\n        _dat_boug = GriddedData(\n            lon       = info[model]['lon'],\n            lat       = info[model]['lat'],\n            is_slon   = False,\n            data_dict = {'boug': dat},\n            metadata  = metadata,\n        )\n\n\n\n    else:\n        raise ValueError(f\"THE DEVELOPER MESSED UP. THIS SHOULD NOT HAPPEN.\")\n\n    return\n</code></pre>"},{"location":"usage/datasets/Crust/dichotomy/get_coords/","title":"get_coords()","text":""},{"location":"usage/datasets/Crust/dichotomy/get_coords/#redplanet.Crust.dichotomy.get_coords","title":"redplanet.Crust.dichotomy.get_coords","text":"<pre><code>get_coords() -&gt; ndarray\n</code></pre> <p>Get a list of dichotomy boundary coordinates.</p> <p>The origin of the dataset is not fully clear. We use the file \"dichotomy_coordinates-JAH-0-360.txt\" (0.046 MiB) downloaded from Wieczorek (2022). They attribute the data to \"Andrews-Hanna et al. (2008)\" which is ambiguous (to me atleast, I could be missing something obvious) \u2014 my best guess is Andrews-Hanna et al. (2008).</p> <p>Returns:</p> Type Description <code>np.ndarray</code> <p>A numpy array of shape <code>(n, 2)</code> where <code>n</code> is the number of coordinates, and the two columns are longitude (0-&gt;360) and latitude respectively.</p> References <ol> <li>Andrews-Hanna, J. C., Zuber, M. T., &amp; Banerdt, W. B. (2008). The Borealis basin and the origin of the martian crustal dichotomy. Nature, 453(7199), 1212-1215. https://doi.org/10.1038/nature07011</li> <li>Wieczorek, M. A. (2022). InSight Crustal Thickness Archive [Dataset]. Zenodo. https://doi.org/10.5281/zenodo.6477509 [Data from \"dichotomy/\" is mirrored to https://rutgers.box.com/v/redplanet-data]</li> </ol> Source code in <code>src/redplanet/Crust/dichotomy.py</code> <pre><code>@substitute_docstrings\ndef get_coords() -&gt; np.ndarray:\n    \"\"\"\n    Get a list of dichotomy boundary coordinates.\n\n    The origin of the dataset is not fully clear. We use the file \"dichotomy_coordinates-JAH-0-360.txt\" (0.046 MiB) downloaded from {@Wieczorek2022_icta.n}. They attribute the data to *\"Andrews-Hanna et al. (2008)\"* which is ambiguous (to me atleast, I could be missing something obvious) \u2014 my best guess is {@dichotomy_paper.n}.\n\n    Returns\n    -------\n    np.ndarray\n        A numpy array of shape `(n, 2)` where `n` is the number of coordinates, and the two columns are longitude (0-&gt;360) and latitude respectively.\n    \"\"\"\n    fpath = _get_fpath_dataset('dichotomy_coords')\n    dat_dichotomy_coords = np.loadtxt(fpath)\n    return dat_dichotomy_coords\n</code></pre>"},{"location":"usage/datasets/Crust/dichotomy/is_above/","title":"is_above(...)","text":""},{"location":"usage/datasets/Crust/dichotomy/is_above/#redplanet.Crust.dichotomy.is_above","title":"redplanet.Crust.dichotomy.is_above","text":"<pre><code>is_above(\n    lon: float | numpy.ndarray,\n    lat: float | numpy.ndarray,\n    as_xarray: bool = False,\n) -&gt; bool | numpy.ndarray | xarray.core.dataarray.DataArray\n</code></pre> <p>Determine if the given point(s) are above the dichotomy boundary.</p> <p>See <code>help(redplanet.Crust.dichotomy.get_coords)</code> for the source of the dichotomy boundary coordinates data.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>float | np.ndarray</code> <p>Longitude coordinate(s) in range [-180, 360].</p> required <code>lat</code> <code>float | np.ndarray</code> <p>Latitude coordinate(s) in range [-90, 90].</p> required <code>as_xarray</code> <code>bool</code> <p>If True, return the data as an <code>xarray.DataArray</code>. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool | np.ndarray | xr.DataArray</code> <p>Boolean array indicating whether the input coordinates are above the dichotomy boundary. If both inputs are 1D numpy arrays then it returns a 2D numpy array with shape <code>(len(lat), len(lon))</code>.</p> Source code in <code>src/redplanet/Crust/dichotomy.py</code> <pre><code>@substitute_docstrings\ndef is_above(\n    lon       : float | np.ndarray,\n    lat       : float | np.ndarray,\n    as_xarray : bool = False,\n) -&gt; bool | np.ndarray | xr.DataArray:\n    \"\"\"\n    Determine if the given point(s) are above the dichotomy boundary.\n\n    See `help(redplanet.Crust.dichotomy.get_coords)` for the source of the dichotomy boundary coordinates data.\n\n    Parameters\n    ----------\n    {param.lon}\n    {param.lat}\n    {param.as_xarray}\n\n    Returns\n    -------\n    bool | np.ndarray | xr.DataArray\n        Boolean array indicating whether the input coordinates are above the dichotomy boundary. If both inputs are 1D numpy arrays then it returns a 2D numpy array with shape `(len(lat), len(lon))`.\n    \"\"\"\n\n    ## input validation\n    _verify_coords(lon, lat)\n    lon = _slon2plon(lon)\n\n    lon = np.atleast_1d(lon)\n    lat = np.atleast_1d(lat)\n\n    ## load dataset\n    dat_dichotomy_coords = get_coords()\n\n    ## for each input longitude, find nearest dichotomy coordinates\n    i_lons = np.searchsorted(dat_dichotomy_coords[:,0], lon, side='right') - 1\n    llons, llats = dat_dichotomy_coords[i_lons].T\n    rlons, rlats = dat_dichotomy_coords[i_lons+1].T\n\n    ## linear interpolate between two nearest dichotomy coordinates to find threshold latitude\n    tlats = llats + (rlats - llats) * ( (lon - llons) / (rlons - llons) )\n\n    ## compare shape(y,1) with shape(x), which broadcasts to shape(y,x) with element-wise comparison\n    result = lat[:, None] &gt;= tlats\n\n    ## remove singleton arrays/dimensions (i.e. one or both inputs were scalars)\n    result = np.squeeze(result)\n    if result.size == 1:\n        return result.item()\n\n    elif as_xarray:\n        result = xr.DataArray(\n            result,\n            dims   = (\"lat\", \"lon\"),\n            coords = {\"lat\": lat, \"lon\": lon},\n        )\n        # result = result.sortby('lat').sortby('lon')\n    return result\n</code></pre>"},{"location":"usage/datasets/Crust/moho/get/","title":"get(...)","text":""},{"location":"usage/datasets/Crust/moho/get/#redplanet.Crust.moho.get","title":"redplanet.Crust.moho.get","text":"<pre><code>get(\n    lon: float | numpy.ndarray,\n    lat: float | numpy.ndarray,\n    crthick: bool = False,\n    as_xarray: bool = False,\n) -&gt; (\n    float | numpy.ndarray | xarray.core.dataarray.DataArray\n)\n</code></pre> <p>Get Mohorovi\u010di\u0107 discontinuity depth (or derived crustal thickness) values at the specified coordinates. Dataset must be loaded first, see <code>redplanet.Crust.moho.load(...)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>float | np.ndarray</code> <p>Longitude coordinate(s) in range [-180, 360].</p> required <code>lat</code> <code>float | np.ndarray</code> <p>Latitude coordinate(s) in range [-90, 90].</p> required <code>crthick</code> <code>bool</code> <p>If True, return crustal thickness values, which is just the difference between the moho and a spherical harmonic model of topography evaluated to the same degree (same method as Wieczorek (2022)). Default is False.</p> <code>False</code> <code>as_xarray</code> <code>bool</code> <p>If True, return the data as an <code>xarray.DataArray</code>. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>float | np.ndarray | xr.DataArray</code> <p>Data values at the the input coordinates. The return type is determined as follows:</p> <ul> <li>float: if both <code>lon</code> and <code>lat</code> are floats.</li> <li>numpy.ndarray (1D): if one of <code>lon</code> or <code>lat</code> is a numpy 1D array and the other is a float.</li> <li>numpy.ndarray (2D): if both <code>lon</code> and <code>lat</code> are numpy 1D arrays. The first dimension of output array corresponds to <code>lat</code> values.</li> <li>xarray.DataArray: see <code>as_xarray</code> parameter (this takes precedence over the above types).</li> </ul> <p>Units are meters [m].</p> References <ol> <li>Wieczorek, M. A. (2022). InSight Crustal Thickness Archive [Dataset]. Zenodo. https://doi.org/10.5281/zenodo.6477509 [Data from \"dichotomy/\" is mirrored to https://rutgers.box.com/v/redplanet-data]</li> </ol> Source code in <code>src/redplanet/Crust/moho/getter.py</code> <pre><code>@substitute_docstrings\ndef get(\n    lon       : float | np.ndarray,\n    lat       : float | np.ndarray,\n    crthick   : bool = False,\n    as_xarray : bool = False\n) -&gt; float | np.ndarray | xr.DataArray:\n    \"\"\"\n    Get Mohorovi\u010di\u0107 discontinuity depth (or derived crustal thickness) values at the specified coordinates. Dataset must be loaded first, see `redplanet.Crust.moho.load(...)`.\n\n    Parameters\n    ----------\n    {param.lon}\n    {param.lat}\n    crthick : bool, optional\n        If True, return crustal thickness values, which is just the difference between the moho and a spherical harmonic model of topography evaluated to the same degree (same method as {@Wieczorek2022_icta.n}). Default is False.\n    {param.as_xarray}\n\n    Returns\n    -------\n    {return.GriddedData}\n\n        Units are meters [m].\n    \"\"\"\n\n    dat_moho = get_dataset()\n\n    return dat_moho.get_values(\n        lon = lon,\n        lat = lat,\n        var = 'crthick' if crthick else 'moho',\n        as_xarray = as_xarray,\n    )\n</code></pre>"},{"location":"usage/datasets/Crust/moho/get_dataset/","title":"get_dataset()","text":""},{"location":"usage/datasets/Crust/moho/get_dataset/#redplanet.Crust.moho.get_dataset","title":"redplanet.Crust.moho.get_dataset","text":"<pre><code>get_dataset() -&gt; GriddedData\n</code></pre> <p>Get the underlying dataset which is currently loaded.</p> <p>Returns:</p> Type Description <code>GriddedData</code> <p>Instance of RedPlanet's <code>GriddedData</code> class, which stores all coordinate/data/metadata information and accessing/plotting methods.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset has not been loaded yet (see the <code>load</code> function for this module).</p> See Also <p><code>redplanet.helper_functions.GriddedData</code></p> Source code in <code>src/redplanet/Crust/moho/loader.py</code> <pre><code>@substitute_docstrings\ndef get_dataset() -&gt; GriddedData:\n    \"\"\"\n    {fulldoc.get_dataset_GriddedData}\n    \"\"\"\n    if _dat_moho is None:\n        raise ValueError('Moho dataset not loaded. Use `redplanet.Crust.moho.load(&lt;model_params&gt;)`.')\n    return _dat_moho\n</code></pre>"},{"location":"usage/datasets/Crust/moho/get_metadata/","title":"get_metadata()","text":""},{"location":"usage/datasets/Crust/moho/get_metadata/#redplanet.Crust.moho.get_metadata","title":"redplanet.Crust.moho.get_metadata","text":"<pre><code>get_metadata() -&gt; dict\n</code></pre> <p>Get metadata for the dataset which is currently loaded.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Contains information about the dataset such as description, units, references, download links, local file path, etc.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset has not been loaded yet (see the <code>load</code> function for this module).</p> Source code in <code>src/redplanet/Crust/moho/loader.py</code> <pre><code>@substitute_docstrings\ndef get_metadata() -&gt; dict:\n    \"\"\"\n    {fulldoc.get_metadata}\n    \"\"\"\n    return dict(get_dataset().metadata)\n</code></pre>"},{"location":"usage/datasets/Crust/moho/get_registry/","title":"get_registry()","text":""},{"location":"usage/datasets/Crust/moho/get_registry/#redplanet.Crust.moho.get_registry","title":"redplanet.Crust.moho.get_registry","text":"<pre><code>get_registry() -&gt; DataFrame\n</code></pre> <p>Get a list of all available Moho models.</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>DataFrame with the following columns: ['interior_model', 'insight_thickness', 'rho_south', 'rho_north']. For an explanation of these columns, see parameters of <code>redplanet.Crust.moho.load()</code>.</p> Source code in <code>src/redplanet/Crust/moho/consts.py</code> <pre><code>def get_registry() -&gt; pd.DataFrame:\n    \"\"\"\n    Get a list of all available Moho models.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with the following columns: ['interior_model', 'insight_thickness', 'rho_south', 'rho_north']. For an explanation of these columns, see parameters of `redplanet.Crust.moho.load()`.\n    \"\"\"\n    registry = pd.read_csv(\n        _get_fpath_dataset('moho_registry'),\n        usecols = ['model_name'],\n    )\n    registry = registry['model_name'].str.split('-', expand=True)\n    registry.columns = ['interior_model', 'insight_thickness', 'rho_south', 'rho_north']\n    registry.iloc[:,1:] = registry.iloc[:,1:].astype(int)\n    return registry\n</code></pre>"},{"location":"usage/datasets/Crust/moho/load/","title":"load(...)","text":""},{"location":"usage/datasets/Crust/moho/load/#redplanet.Crust.moho.load","title":"redplanet.Crust.moho.load","text":"<pre><code>load(\n    interior_model: str,\n    insight_thickness: int | str,\n    rho_south: int | str,\n    rho_north: int | str,\n    fail_silently: bool = False,\n) -&gt; None | bool\n</code></pre> <p>Load a model of the Mohorovi\u010di\u0107 discontinuity (crust-mantle interface) with the given parameters. For a list of valid combinations of parameters (total 21,894 options), run <code>redplanet.Crust.moho.get_registry()</code> (returns a pandas DataFrame).</p> <p>Spherical harmonic coefficients are precomputed in Wieczorek (2022) and downloaded on-the-fly from our own mirror. The full paper discusses/analyzes the models in detail (Wieczorek et al., 2022). We process spherical harmonic coefficients with <code>pyshtools</code> (Wieczorek et al., 2024; Wieczorek &amp; Meschede, 2018).</p> <p>NOTE: Each moho file is about 228 KiB. These typically download in a fraction of a second (assuming you're accessing a model first time), so poor performance is likely due to poor internet connection.</p> <p>Parameters:</p> Name Type Description Default <code>interior_model</code> <code>str</code> <p>Name of the interior model used for the mantle and core (see notes for more information).</p> <p>Options are: ['DWAK', 'DWThot', 'DWThotCrust1', 'DWThotCrust1r', 'EH45Tcold', 'EH45TcoldCrust1', 'EH45TcoldCrust1r', 'EH45ThotCrust2', 'EH45ThotCrust2r', 'Khan2022', 'LFAK', 'SANAK', 'TAYAK', 'YOTHotRc1760kmDc40km', 'YOTHotRc1810kmDc40km', 'ZG_DW']. See notes for more information.</p> required <code>insight_thickness</code> <code>int | str</code> <p>Assumed crustal thickness beneath the InSight landing site, in km.</p> required <code>rho_south</code> <code>int | str</code> <p>Average crustal thickness south of the dichotomy boundary, in kg/m^3.</p> required <code>rho_north</code> <code>int | str</code> <p>Average crustal thickness north of the dichotomy boundary, in kg/m^3.</p> required <code>fail_silently</code> <code>bool</code> <ul> <li>If False (default), raise <code>MohoDatasetNotFoundError</code> if there is no dataset for the given parameters.</li> <li>If True, return True if the dataset was loaded successfully, or False if there is no dataset for the given parameters.</li> </ul> <code>False</code> <p>Returns:</p> Type Description <code>None | bool</code> <p>Return is determined as follows:</p> Successfully Loaded Model Doesn't Exist fail_silently=False <code>None</code> Raise <code>MohoDatasetNotFoundError</code> fail_silently=True <code>True</code> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>interior_model</code> is not one of the available options.</p> <code>MohoDatasetNotFoundError</code> <p>If the dataset is not found and <code>fail_silently</code> is False.</p> Notes <ul> <li>More information on reference interior models:<ul> <li><code>ctplanet</code> function to read reference interior models (we don't use it, but it may be helpful if you're implementing this yourself)</li> <li>interior model files</li> </ul> </li> </ul> References <ol> <li>Wieczorek, M. A. (2022). InSight Crustal Thickness Archive [Dataset]. Zenodo. https://doi.org/10.5281/zenodo.6477509 [Data from \"dichotomy/\" is mirrored to https://rutgers.box.com/v/redplanet-data]</li> <li>Wieczorek, M. A., &amp; Meschede, M. (2018). SHTools: Tools for Working with Spherical Harmonics. Geochemistry, Geophysics, Geosystems, 19(8), 2574-2592. https://doi.org/10.1029/2018GC007529</li> <li>Wieczorek, M. A., Broquet, A., McLennan, S. M., Rivoldini, A., Golombek, M., Antonangeli, D., Beghein, C., Giardini, D., Gudkova, T., Gyalay, S., Johnson, C. L., Joshi, R., Kim, D., King, S. D., Knapmeyer-Endrun, B., Lognonn\u00e9, P., Michaut, C., Mittelholz, A., Nimmo, F., Ojha, L., Panning, M. P., Plesa, A., Siegler, M. A., Smrekar, S. E., Spohn, T., &amp; Banerdt, W. B. (2022). InSight Constraints on the Global Character of the Martian Crust. Journal of Geophysical Research: Planets, 127(5), e2022JE007298. https://doi.org/10.1029/2022JE007298</li> <li>Wieczorek, M. A., Meschede, M., Broquet, A., Brugere, T., Corbin, A., EricAtORS, Hattori, A., Kalinin, A., Kohler, J., Kutra, D., Leinweber, K., Lobo, P., Maia, J., Mentzer, E., Minton, D., Oshchepkov, I., Phan, P. L., Poplawski, O., Reinecke, M., Sales de Andrade, E., Schnetter, E., Schr\u00f6der, S., Shin, D., Sierra, J., Vasishta, A., Walker, A., xoviat, &amp; Xu, B. (2024). SHTOOLS/SHTOOLS: Version 4.13.1. Zenodo. https://doi.org/10.5281/zenodo.12698962</li> </ol> Source code in <code>src/redplanet/Crust/moho/loader.py</code> <pre><code>@substitute_docstrings\ndef load(\n    interior_model    : str,\n    insight_thickness : int | str,\n    rho_south         : int | str,\n    rho_north         : int | str,\n    fail_silently     : bool = False,    ##  False [default] -&gt; return None,  True -&gt; return type(bool)\n) -&gt; None | bool:\n    \"\"\"\n    Load a model of the Mohorovi\u010di\u0107 discontinuity (crust-mantle interface) with the given parameters. For a list of valid combinations of parameters (total 21,894 options), run `redplanet.Crust.moho.get_registry()` (returns a pandas DataFrame).\n\n    Spherical harmonic coefficients are precomputed in {@Wieczorek2022_icta.n} and downloaded on-the-fly from our own mirror. The full paper discusses/analyzes the models in detail ({@Wieczorek2022_icta_paper.p}). We process spherical harmonic coefficients with `pyshtools` ({@shtools_code.p}; {@shtools_paper.p}).\n\n    NOTE: Each moho file is about 228 KiB. These typically download in a fraction of a second (assuming you're accessing a model first time), so poor performance is likely due to poor internet connection.\n\n\n    Parameters\n    ----------\n    interior_model : str\n        Name of the interior model used for the mantle and core (see notes for more information).\n\n        Options are: ['DWAK', 'DWThot', 'DWThotCrust1', 'DWThotCrust1r', 'EH45Tcold', 'EH45TcoldCrust1', 'EH45TcoldCrust1r', 'EH45ThotCrust2', 'EH45ThotCrust2r', 'Khan2022', 'LFAK', 'SANAK', 'TAYAK', 'YOTHotRc1760kmDc40km', 'YOTHotRc1810kmDc40km', 'ZG_DW']. See notes for more information.\n    insight_thickness : int | str\n        Assumed crustal thickness beneath the InSight landing site, in km.\n    rho_south : int | str\n        Average crustal thickness south of the dichotomy boundary, in kg/m^3.\n    rho_north : int | str\n        Average crustal thickness north of the dichotomy boundary, in kg/m^3.\n    fail_silently : bool, optional\n        - If False (default), raise `MohoDatasetNotFoundError` if there is no dataset for the given parameters.\n        - If True, return True if the dataset was loaded successfully, or False if there is no dataset for the given parameters.\n\n\n    Returns\n    -------\n    None | bool\n        Return is determined as follows:\n\n        |                         | **Successfully Loaded** | **Model Doesn't Exist**          |\n        | ----------------------- | ----------------------- | -------------------------------- |\n        | **fail_silently=False** | `None`                  | Raise `MohoDatasetNotFoundError` |\n        | **fail_silently=True**  | `True`                  | `False`                          |\n\n\n    Raises\n    ------\n    ValueError\n        If `interior_model` is not one of the available options.\n    MohoDatasetNotFoundError\n        If the dataset is not found and `fail_silently` is False.\n\n\n    Notes\n    -----\n    - More information on reference interior models:\n        - [`ctplanet` function to read reference interior models (we don't use it, but it may be helpful if you're implementing this yourself)](https://markwieczorek.github.io/ctplanet/source/generated/ctplanet.ReadRefModel.html){target=\"_blank\"}\n        - [interior model files](https://github.com/MarkWieczorek/ctplanet/tree/74e8550080d4adc68ae291a500e8d198a40d437c/examples/Data/Mars-reference-interior-models){target=\"_blank\"}\n    \"\"\"\n\n    ## load moho\n\n    if interior_model not in _interior_models:\n        raise ValueError(\n            f'Unknown interior model: \"{interior_model}\".\\n'\n            f'Options are: {\", \".join(_interior_models)}.'\n        )\n\n    try:\n        fpath_moho = _get_fpath_dataset(\n            f'Moho-Mars-{interior_model}-{insight_thickness}-{rho_south}-{rho_north}'\n        )\n    except MohoDatasetNotFoundError as e:\n        if fail_silently:\n            return False\n        else:\n            raise\n\n    ds_moho = (\n        pysh.SHCoeffs.from_file(fpath_moho)\n        .expand()\n        .to_xarray()\n        .isel(lat=slice(None, None, -1))  ## in pysh, lats are always decreasing at first\n    )\n\n\n\n    ## load shape\n\n    fpath_shape = _get_fpath_dataset('MOLA_shape_719')\n\n    ds_shape = (\n        pysh.SHCoeffs.from_file(\n            fpath_shape,\n            lmax   = 90,\n            format = 'bshc'\n        )\n        .expand()\n        .to_xarray()\n        .isel(lat=slice(None, None, -1))\n    )\n\n\n\n    ## GriddedData\n\n    global _dat_moho\n\n    _dat_moho = GriddedData(\n        lon       = ds_moho.lon.values,\n        lat       = ds_moho.lat.values,\n        is_slon   = False,\n        data_dict = {\n            'moho'   : ds_moho.values,\n            'crthick': (ds_shape - ds_moho).values,\n        },\n        metadata  = {\n            'title': f'{interior_model}-{insight_thickness}-{rho_south}-{rho_north}',\n            'units': 'm',\n            'model_params': {\n                'interior_model'      : interior_model,\n                'insight_thickness_km': insight_thickness,\n                'rho_south'           : rho_south,\n                'rho_north'           : rho_north,\n            },\n            'lmax': 90,\n            'source' : 'https://doi.org/10.5281/zenodo.6477509',\n            'fpath': fpath_moho,\n        },\n    )\n\n\n\n    if fail_silently:\n        return True\n    return\n</code></pre>"},{"location":"usage/datasets/Crust/topo/get/","title":"get(...)","text":""},{"location":"usage/datasets/Crust/topo/get/#redplanet.Crust.topo.get","title":"redplanet.Crust.topo.get","text":"<pre><code>get(\n    lon: float | numpy.ndarray,\n    lat: float | numpy.ndarray,\n    as_xarray: bool = False,\n) -&gt; (\n    float | numpy.ndarray | xarray.core.dataarray.DataArray\n)\n</code></pre> <p>Get topography values at the specified coordinates. Dataset must be loaded first, see <code>redplanet.Crust.topo.load(...)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>float | np.ndarray</code> <p>Longitude coordinate(s) in range [-180, 360].</p> required <code>lat</code> <code>float | np.ndarray</code> <p>Latitude coordinate(s) in range [-90, 90].</p> required <code>as_xarray</code> <code>bool</code> <p>If True, return the data as an <code>xarray.DataArray</code>. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>float | np.ndarray | xr.DataArray</code> <p>Data values at the the input coordinates. The return type is determined as follows:</p> <ul> <li>float: if both <code>lon</code> and <code>lat</code> are floats.</li> <li>numpy.ndarray (1D): if one of <code>lon</code> or <code>lat</code> is a numpy 1D array and the other is a float.</li> <li>numpy.ndarray (2D): if both <code>lon</code> and <code>lat</code> are numpy 1D arrays. The first dimension of output array corresponds to <code>lat</code> values.</li> <li>xarray.DataArray: see <code>as_xarray</code> parameter (this takes precedence over the above types).</li> </ul> <p>Units are meters [m].</p> Source code in <code>src/redplanet/Crust/topo/getter.py</code> <pre><code>@substitute_docstrings\ndef get(\n    lon       : float | np.ndarray,\n    lat       : float | np.ndarray,\n    as_xarray : bool = False\n) -&gt; float | np.ndarray | xr.DataArray:\n    \"\"\"\n    Get topography values at the specified coordinates. Dataset must be loaded first, see `redplanet.Crust.topo.load(...)`.\n\n    Parameters\n    ----------\n    {param.lon}\n    {param.lat}\n    {param.as_xarray}\n\n    Returns\n    -------\n    {return.GriddedData}\n\n        Units are meters [m].\n    \"\"\"\n\n    dat_topo = get_dataset()\n\n    return dat_topo.get_values(\n        lon = lon,\n        lat = lat,\n        var = 'topo',\n        as_xarray = as_xarray,\n    )\n</code></pre>"},{"location":"usage/datasets/Crust/topo/get_dataset/","title":"get_dataset()","text":""},{"location":"usage/datasets/Crust/topo/get_dataset/#redplanet.Crust.topo.get_dataset","title":"redplanet.Crust.topo.get_dataset","text":"<pre><code>get_dataset() -&gt; GriddedData\n</code></pre> <p>Get the underlying dataset which is currently loaded.</p> <p>Returns:</p> Type Description <code>GriddedData</code> <p>Instance of RedPlanet's <code>GriddedData</code> class, which stores all coordinate/data/metadata information and accessing/plotting methods.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset has not been loaded yet (see the <code>load</code> function for this module).</p> See Also <p><code>redplanet.helper_functions.GriddedData</code></p> Source code in <code>src/redplanet/Crust/topo/loader.py</code> <pre><code>@substitute_docstrings\ndef get_dataset() -&gt; GriddedData:\n    \"\"\"\n    {fulldoc.get_dataset_GriddedData}\n    \"\"\"\n    if _dat_topo is None:\n        raise ValueError('Topography dataset not loaded. Use `redplanet.Crust.topo.load(&lt;model_params&gt;)`.')\n    return _dat_topo\n</code></pre>"},{"location":"usage/datasets/Crust/topo/get_metadata/","title":"get_metadata()","text":""},{"location":"usage/datasets/Crust/topo/get_metadata/#redplanet.Crust.topo.get_metadata","title":"redplanet.Crust.topo.get_metadata","text":"<pre><code>get_metadata() -&gt; dict\n</code></pre> <p>Get metadata for the dataset which is currently loaded.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Contains information about the dataset such as description, units, references, download links, local file path, etc.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset has not been loaded yet (see the <code>load</code> function for this module).</p> Source code in <code>src/redplanet/Crust/topo/loader.py</code> <pre><code>@substitute_docstrings\ndef get_metadata() -&gt; dict:\n    \"\"\"\n    {fulldoc.get_metadata}\n    \"\"\"\n    return dict(get_dataset().metadata)\n</code></pre>"},{"location":"usage/datasets/Crust/topo/load/","title":"load(...)","text":""},{"location":"usage/datasets/Crust/topo/load/#redplanet.Crust.topo.load","title":"redplanet.Crust.topo.load","text":"<pre><code>load(model: str = None) -&gt; None\n</code></pre> <p>Load a topography model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Name of the topography model to load. Options are:</p> <ul> <li><code>'SH_10km'</code> (17 MB) \u2014 Spherical harmonic model of topography from Wieczorek (2024) evaluated to degree 1066, corresponding to a spatial resolution of 10 km.</li> <li><code>'SH_5km'</code> (70 MB) \u2014 Same as <code>'SH_10km'</code> but evaluated to degree 2133, corresponding to a spatial resolution of 5 km.</li> <li><code>'DEM_463m'</code> (2 GB) \u2014 MGS MOLA Digital Elevation Model 463m (Goddard Space Flight Center, 2003).</li> <li><code>'DEM_200m'</code> (11 GB) \u2014 MGS MOLA - MEX HRSC Blended Digital Elevation Model 200m (Fergason et al., 2018).</li> </ul> <p>NOTE: Higher resolution models are only slightly slower than lower resolution models. Our loading/accessing methods are already highly optimized (arrays are memory-mapped so they don't occupy RAM, e.g. accessing a global grid of 1e6 points takes ~0.01 seconds). Regardless, if you only want to download the smallest necessary dataset, we recommend 'SH' models for global maps and 'DEM' models for local maps (e.g. craters). In our experience, the <code>'DEM_463m'</code> model is sufficient for almost all purposes (hence it's included in <code>prefetch</code> and the default for plotting hillshade).</p> <p>For description of our modifications to the original data, see notes section.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid model name is provided.</p> Notes <p>For 'SH_' options, we start with a spherical harmonic model of the shape of Mars based on MOLA data, provided by Wieczorek (2024). Then we subtract the geoid height and geoid reference radius, which yields the planet's surface relief with respect to the geoid (i.e. topography). We assume a spherical harmonic model of degree \\(L\\) has spatial resolution \\(\\frac{2 \\pi R_{\\text{Mars}}}{2L+1}\\). Results are saved as a binary file, which can be loaded as a memory-mapped 2D numpy array of 16-bit integers for very fast access speeds without occupying RAM. For more information and our code, see \"datasets/Crust/topo/SH\" in the GitHub repo. -- TODO*</p> <p>For 'DEM_' options, we modify the original data files by reprojecting to the \"Mars 2000 Sphere\" model (radius = 3,396,190 km). We convert the original \"TIFF\" file format to a binary file, which can be loaded as a memory-mapped 2D numpy array of 16-bit integers for very fast access speeds without occupying RAM. For more information and our code, see \"datasets/Crust/topo/DEM\" in the GitHub repo. -- TODO*</p> <ul> <li>I'll eventually have a section on my website to describe datasets and how we modified them -- add a link to that here.</li> </ul> References <ol> <li>Fergason, R. L., Hare, T. M., &amp; Laura, J. (2018). Mars MGS MOLA - MEX HRSC Blended DEM Global 200m v2 [Dataset]. Astrogeology PDS Annex, U.S. Geological Survey. https://astrogeology.usgs.gov/search/map/mars_mgs_mola_mex_hrsc_blended_dem_global_200m</li> <li>Goddard Space Flight Center (2003). Mars MGS MOLA DEM 463m [Dataset]. Astrogeology PDS Annex, U.S. Geological Survey. https://astrogeology.usgs.gov/search/map/mars_mgs_mola_dem_463m</li> <li>Wieczorek, M. (2024). Spherical harmonic models of the shape of Mars (MOLA) [Dataset]. Zenodo. https://doi.org/10.5281/zenodo.10820719</li> </ol> Source code in <code>src/redplanet/Crust/topo/loader.py</code> <pre><code>@substitute_docstrings\ndef load(model: str = None) -&gt; None:\n    \"\"\"\n    Load a topography model.\n\n    Parameters\n    ----------\n    model : str\n        Name of the topography model to load. Options are:\n\n        - `'SH_10km'` (17 MB) \u2014 Spherical harmonic model of topography from {@MOLA_shcoeffs.n} evaluated to degree 1066, corresponding to a spatial resolution of 10 km.\n        - `'SH_5km'` (70 MB) \u2014 Same as `'SH_10km'` but evaluated to degree 2133, corresponding to a spatial resolution of 5 km.\n        - `'DEM_463m'` (2 GB) \u2014 MGS MOLA Digital Elevation Model 463m ({@DEM_463m.p}).\n        - `'DEM_200m'` (11 GB) \u2014 MGS MOLA - MEX HRSC Blended Digital Elevation Model 200m ({@DEM_200m.p}).\n\n        **NOTE:** Higher resolution models are only *slightly* slower than lower resolution models. Our loading/accessing methods are already highly optimized (arrays are memory-mapped so they don't occupy RAM, e.g. accessing a global grid of 1e6 points takes ~0.01 seconds). Regardless, if you only want to download the smallest necessary dataset, we recommend 'SH' models for global maps and 'DEM' models for local maps (e.g. craters). In our experience, the `'DEM_463m'` model is sufficient for almost all purposes (hence it's included in `prefetch` and the default for plotting hillshade).\n\n        For description of our modifications to the original data, see notes section.\n\n    Raises\n    ------\n    ValueError\n        If an invalid model name is provided.\n\n    Notes\n    -----\n    For 'SH_' options, we start with a spherical harmonic model of the shape of Mars based on MOLA data, provided by {@MOLA_shcoeffs.n}. Then we subtract the geoid height and geoid reference radius, which yields the planet's surface relief with respect to the geoid (i.e. topography). We assume a spherical harmonic model of degree $L$ has spatial resolution $\\\\frac{2 \\\\pi R_{\\\\text{Mars}}}{2L+1}$. Results are saved as a binary file, which can be loaded as a memory-mapped 2D numpy array of 16-bit integers for very fast access speeds without occupying RAM. For more information and our code, see [\"datasets/Crust/topo/SH\" in the GitHub repo.](https://github.com/Humboldt-Penguin/redplanet/tree/main/datasets/Crust/topo/SH){target=\"_blank\"} -- TODO*\n\n    For 'DEM_' options, we modify the original data files by reprojecting to the \"Mars 2000 Sphere\" model (radius = 3,396,190 km). We convert the original \"TIFF\" file format to a binary file, which can be loaded as a memory-mapped 2D numpy array of 16-bit integers for very fast access speeds without occupying RAM. For more information and our code, see [\"datasets/Crust/topo/DEM\" in the GitHub repo.](https://github.com/Humboldt-Penguin/redplanet/tree/main/datasets/Crust/topo/DEM){target=\"_blank\"} -- TODO*\n\n    * I'll eventually have a section on my website to describe datasets and how we modified them -- add a link to that here.\n    \"\"\"\n\n    info = {\n        'SH_10km': {\n            'shape': (2135, 4269),\n            'dtype': np.int16,\n            'lon': np.linspace(0, 360, 4269),\n            'lat': np.linspace(-90, 90, 2135),\n            'metadata': {\n                'title': 'Spherical harmonic models of the shape of Mars (MOLA) \u2014 10 km resolution, corresponding to degree 1066',\n                'units': 'm',\n                'citation': 'Wieczorek, M. (2024). Spherical harmonic models of the shape of Mars (MOLA) [Dataset]. Zenodo. https://doi.org/10.5281/zenodo.10820719',\n                'meters_per_pixel': 10_000 / 2,  ## NOTE: The effective spatial resolution of a spherical harmonic model of degree L is given by (2*pi*R)/(2L+1), in this case 1066 -&gt; 10 km. The expansion yields a finer grid than we'd expect, but its only interpolating between independent resolution elements defined by the bandlimit.\n            },\n        },\n        'SH_5km': {\n            'shape': (4269, 8537),\n            'dtype': np.int16,\n            'lon': np.linspace(0, 360, 8537),\n            'lat': np.linspace(-90, 90, 4269),\n            'metadata': {\n                'title': 'Spherical harmonic models of the shape of Mars (MOLA) \u2014 5 km resolution, corresponding to degree 2133',\n                'units': 'm',\n                'citation': 'Wieczorek, M. (2024). Spherical harmonic models of the shape of Mars (MOLA) [Dataset]. Zenodo. https://doi.org/10.5281/zenodo.10820719',\n                'meters_per_pixel': 5_000 / 2,\n            },\n        },\n        'DEM_463m': {\n            'shape': (23041, 46081),\n            'dtype': np.int16,\n            'lon': -179.9960938347692 + 0.007812330461578525 * np.arange(46081),\n            'lat': -89.99376946560506 + 0.00781206004494716  * np.arange(23041),\n            'nan_value': -99_999,  ## data is stored as int16 which doesn't support `np.nan`, so we use this sentinel value.\n            'metadata': {\n                'title': 'Mars MGS MOLA DEM 463m',\n                'units': 'm',\n                'citation': 'Goddard Space Flight Center (2003). Mars MGS MOLA DEM 463m [Dataset]. Astrogeology PDS Annex, U.S. Geological Survey. https://astrogeology.usgs.gov/search/map/mars_mgs_mola_dem_463m',\n                'meters_per_pixel': 463,\n            },\n        },\n        'DEM_200m': {\n            'shape': (53347, 106694),\n            'dtype': np.int16,\n            'lon': -179.9983129395848 + 0.0033741208306410017 * np.arange(106694),\n            'lat': -89.99753689179012 + 0.0033741208306410004 * np.arange(53347),\n            'nan_value': -99_999,  ## data is stored as int16 which doesn't support `np.nan`, so we use this sentinel value.\n            'metadata': {\n                'title': 'Mars MGS MOLA - MEX HRSC Blended DEM Global 200m',\n                'units': 'm',\n                'citation': 'Fergason, R. L., Hare, T. M., &amp; Laura, J. (2018). Mars MGS MOLA - MEX HRSC Blended DEM Global 200m v2 [Dataset]. Astrogeology PDS Annex, U.S. Geological Survey. https://astrogeology.usgs.gov/search/map/mars_mgs_mola_mex_hrsc_blended_dem_global_200m',\n                'meters_per_pixel': 200,\n            },\n        },\n    }\n\n    if model not in info:\n        raise ValueError(f\"Invalid topography model: '{model}'. Options are: {list(info.keys())}.\")\n\n\n    # if model.startswith('DEM_'):\n\n    fpath = _get_fpath_dataset(model)\n\n    dat = np.memmap(\n        fpath,\n        mode  = 'r',\n        dtype = info[model]['dtype'],\n        shape = info[model]['shape'],\n    )\n\n    metadata = info[model]['metadata']\n    metadata['fpath'] = fpath\n    metadata['short_name'] = model\n\n    is_slon = info[model]['lon'][0] &lt; 0\n\n    global _dat_topo\n    _dat_topo = GriddedData(\n        lon       = info[model]['lon'],\n        lat       = info[model]['lat'],\n        is_slon   = is_slon,\n        data_dict = {'topo': dat},\n        metadata  = metadata,\n    )\n\n\n    # else:\n    #     raise ValueError(f\"THE DEVELOPER MESSED UP. THIS SHOULD NOT HAPPEN.\")\n\n    return\n</code></pre>"},{"location":"usage/datasets/GRS/get/","title":"get(...)","text":""},{"location":"usage/datasets/GRS/get/#redplanet.GRS.get","title":"redplanet.GRS.get","text":"<pre><code>get(\n    element: str,\n    lon: float | numpy.ndarray,\n    lat: float | numpy.ndarray,\n    quantity: str = \"concentration\",\n    normalize: bool = False,\n    as_xarray: bool = False,\n) -&gt; (\n    float | numpy.ndarray | xarray.core.dataarray.DataArray\n)\n</code></pre> <p>Get GRS element concentration/sigma values at the specified coordinates.</p> <p>Data (0.41 MiB) is provided by Rani (2022). The full paper discusses/analyzes the models in detail (Rani et al., 2022).</p> <p>Parameters:</p> Name Type Description Default <code>element</code> <code>str</code> <p>Element name. Options are: ['al', 'ca', 'cl', 'fe', 'h2o', 'k', 'si', 's', 'th'].</p> required <code>lon</code> <code>float | np.ndarray</code> <p>Longitude coordinate(s) in range [-180, 360].</p> required <code>lat</code> <code>float | np.ndarray</code> <p>Latitude coordinate(s) in range [-90, 90].</p> required <code>quantity</code> <code>str</code> <p>Return 'concentration' or 'sigma' values, by default 'concentration'.</p> <code>'concentration'</code> <code>normalize</code> <code>bool</code> <p>If True, normalize the element quantity to a volatile-free (Cl, H2O, S) basis, by default False.</p> <p>\"The GRS instrument measures elemental abundances in the top-most tens of centimeters of the Martian surface, and thus is strongly influenced by near-surface soils, ice and dust deposits. These sediments broadly represent the bulk chemistry of the Martian upper crust when renormalized to a volatile-free basis [Taylor and McLennan, 2009] and as such, K and Th values must be renormalized to a H2O-, S-, and Cl-free basis to better reflect bulk crustal values.\" (Hahn et al., 2011)</p> <code>False</code> <code>as_xarray</code> <code>bool</code> <p>If True, return the data as an <code>xarray.DataArray</code>. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>float | np.ndarray | xr.DataArray</code> <p>Data values at the the input coordinates. The return type is determined as follows:</p> <ul> <li>float: if both <code>lon</code> and <code>lat</code> are floats.</li> <li>numpy.ndarray (1D): if one of <code>lon</code> or <code>lat</code> is a numpy 1D array and the other is a float.</li> <li>numpy.ndarray (2D): if both <code>lon</code> and <code>lat</code> are numpy 1D arrays. The first dimension of output array corresponds to <code>lat</code> values.</li> <li>xarray.DataArray: see <code>as_xarray</code> parameter (this takes precedence over the above types).</li> </ul> <p>Units are mass fraction (out of one).</p> <p>Raises:</p> Type Description <code>ValueError</code> <ul> <li><code>element</code> is not one of ['al', 'ca', 'cl', 'fe', 'h2o', 'k', 'si', 's', 'th'].</li> <li><code>quantity</code> is not one of ['concentration', 'sigma'].</li> <li><code>normalize</code> is True and <code>element</code> is one of ['cl', 'h2o', 's'] -- you can't normalize a volatile element to a volatile-free basis!</li> </ul> References <ol> <li>Hahn, B. C., McLennan, S. M., &amp; Klein, E. C. (2011). Martian surface heat production and crustal heat flow from Mars Odyssey Gamma-Ray spectrometry. Geophysical Research Letters, 38(14). https://doi.org/10.1029/2011GL047435</li> <li>Rani, A. (2022). 2001 Mars Odyssey Gamma Ray Spectrometer Element Concentration Maps [Dataset]. Mendeley. https://doi.org/10.17632/3jd9whd78m.1</li> <li>Rani, A., Basu Sarbadhikari, A., Hood, D. R., Gasnault, O., Nambiar, S., &amp; Karunatillake, S. (2022). Consolidated Chemical Provinces on Mars: Implications for Geologic Interpretations. Geophysical Research Letters, 49(14), e2022GL099235. https://doi.org/10.1029/2022GL099235</li> </ol> Source code in <code>src/redplanet/GRS/getter.py</code> <pre><code>@substitute_docstrings\ndef get(\n    element   : str,\n    lon       : float | np.ndarray,\n    lat       : float | np.ndarray,\n    quantity  : str  = 'concentration',\n    normalize : bool = False,\n    as_xarray : bool = False\n) -&gt; float | np.ndarray | xr.DataArray:\n    \"\"\"\n    Get GRS element concentration/sigma values at the specified coordinates.\n\n    Data (0.41 MiB) is provided by {@GRS_data.n}. The full paper discusses/analyzes the models in detail ({@GRS_paper.p}).\n\n\n    Parameters\n    ----------\n    element : str\n        Element name. Options are: ['al', 'ca', 'cl', 'fe', 'h2o', 'k', 'si', 's', 'th'].\n    {param.lon}\n    {param.lat}\n    quantity : str, optional\n        Return 'concentration' or 'sigma' values, by default 'concentration'.\n    normalize : bool, optional\n        If True, normalize the element quantity to a volatile-free (Cl, H2O, S) basis, by default False.\n\n        &gt; \"The GRS instrument measures elemental abundances in the top-most tens of centimeters of the Martian surface, and thus is strongly influenced by near-surface soils, ice and dust deposits. These sediments broadly represent the bulk chemistry of the Martian upper crust when renormalized to a volatile-free basis [Taylor and McLennan, 2009] and as such, K and Th values must be renormalized to a H2O-, S-, and Cl-free basis to better reflect bulk crustal values.\" ({@Hahn2011.p})\n    {param.as_xarray}\n\n\n    Returns\n    -------\n    {return.GriddedData}\n\n        Units are mass fraction (out of one).\n\n\n    Raises\n    ------\n    ValueError\n        - `element` is not one of ['al', 'ca', 'cl', 'fe', 'h2o', 'k', 'si', 's', 'th'].\n        - `quantity` is not one of ['concentration', 'sigma'].\n        - `normalize` is True and `element` is one of ['cl', 'h2o', 's'] -- you can't normalize a volatile element to a volatile-free basis!\n    \"\"\"\n\n    ## input validation\n    e = ['al','ca','cl','fe','h2o','k','si','s','th']\n    v = ['cl','h2o','s']\n    q = ['concentration','sigma']\n\n    if element not in e:\n        raise ValueError(f\"Element {element} is not in list of supported elements: {e}.\")\n\n    if quantity not in q:\n        raise ValueError(f\"Quantity {quantity} is not in list of supported quantities: {q}.\")\n\n    if normalize and (element in v):\n        raise ValueError(f\"Can't normalize a volatile element ('{element}') to a volatile-free (cl, h2o, s) basis.\")\n\n\n    ## get data &amp; normalize\n    dat_grs = get_dataset()\n\n    dat = dat_grs.get_values(\n        lon = lon,\n        lat = lat,\n        var = f'{element}_{quantity}',\n        as_xarray = as_xarray,\n    )\n\n    if normalize:\n        volatiles = dat_grs.get_values(\n            lon = lon,\n            lat = lat,\n            var = f'cl+h2o+s_{quantity}',\n            as_xarray = as_xarray,\n        )\n        dat = dat / (1 - volatiles)\n\n    return dat\n</code></pre>"},{"location":"usage/datasets/GRS/get_dataset/","title":"get_dataset()","text":""},{"location":"usage/datasets/GRS/get_dataset/#redplanet.GRS.get_dataset","title":"redplanet.GRS.get_dataset","text":"<pre><code>get_dataset() -&gt; GriddedData\n</code></pre> <p>Get the underlying dataset which is currently loaded.</p> <p>Returns:</p> Type Description <code>GriddedData</code> <p>Instance of RedPlanet's <code>GriddedData</code> class, which stores all coordinate/data/metadata information and accessing/plotting methods.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset has not been loaded yet (see the <code>load</code> function for this module).</p> See Also <p><code>redplanet.helper_functions.GriddedData</code></p> Source code in <code>src/redplanet/GRS/loader.py</code> <pre><code>@substitute_docstrings\ndef get_dataset() -&gt; GriddedData:\n    \"\"\"\n    {fulldoc.get_dataset_GriddedData}\n    \"\"\"\n    if _dat_grs is None:\n        _load()\n    return _dat_grs\n</code></pre>"},{"location":"usage/datasets/GRS/get_metadata/","title":"get_metadata()","text":""},{"location":"usage/datasets/GRS/get_metadata/#redplanet.GRS.get_metadata","title":"redplanet.GRS.get_metadata","text":"<pre><code>get_metadata() -&gt; dict\n</code></pre> <p>Get metadata for the dataset which is currently loaded.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Contains information about the dataset such as description, units, references, download links, local file path, etc.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset has not been loaded yet (see the <code>load</code> function for this module).</p> Source code in <code>src/redplanet/GRS/loader.py</code> <pre><code>@substitute_docstrings\ndef get_metadata() -&gt; dict:\n    \"\"\"\n    {fulldoc.get_metadata}\n    \"\"\"\n    return dict(get_dataset().metadata)\n</code></pre>"},{"location":"usage/datasets/Mag/depth/get_dataset/","title":"get_dataset(...)","text":""},{"location":"usage/datasets/Mag/depth/get_dataset/#redplanet.Mag.depth.get_dataset","title":"redplanet.Mag.depth.get_dataset","text":"<pre><code>get_dataset(\n    as_dict: bool = False, _extras: bool = False\n) -&gt; pandas.core.frame.DataFrame | list[dict]\n</code></pre> <p>Get the full magnetic source depth dataset.</p> <p>Data (0.038 MiB) is provided by Gong and Wieczorek (2021b). The full paper discusses/analyzes the models in detail (Gong &amp; Wieczorek, 2021a).</p> <p>Parameters:</p> Name Type Description Default <code>as_dict</code> <code>bool</code> <p>If True, return the data as a list of dictionaries. Default is False.</p> <code>False</code> <code>_extras</code> <code>bool</code> <p>Please ignore this, it is used for internal purposes only.</p> <code>False</code> <p>Returns:</p> Type Description <code>pd.DataFrame | list[dict]</code> <p>Information about all 412 dipoles. Columns are:</p> <ul> <li><code>lon</code> : float<ul> <li>Longitude in range [-180, 180].</li> </ul> </li> <li><code>lat</code> : float<ul> <li>Latitude in range [-90, 90].</li> </ul> </li> <li><code>chi_reduced</code> : float<ul> <li>\"reduced chi^2 value of the best fitting model\"</li> </ul> </li> <li><code>cap_radius_km</code> : list[float]<ul> <li>\"angular radii of the magnetized caps (best-fit, and 1-sigma lower/upper limits)\"</li> </ul> </li> <li><code>depth_km</code> : list[float]<ul> <li>\"magnetization depth (best-fit, and 1-sigma lower/upper limits)\"</li> </ul> </li> <li><code>dipole_mment_Am2</code> : list[float]<ul> <li>\"square root of the metric NV^2 [in A m^2] (best-fit, and 1-sigma lower/upper limits)\" <p>Note that the 1-sigma lower/upper values are NaN when the minimum reduced chi^2 value of the best fitting model is outside the 1-sigma confidence level of the reduced chi^2 that were obtained from Monte Carlo simulations.</p> References <ol> <li>Gong, S., &amp; Wieczorek, M. (2021a). Depth of Martian Magnetization From Localized Power Spectrum Analysis. Journal of Geophysical Research: Planets, 126(8), e2020JE006690. https://doi.org/10.1029/2020JE006690</li> <li>Gong, S., &amp; Wieczorek, M. (2021b). Supplementary Data for Depth of Martian Magnetization From Localized Power Spectrum Analysis [Dataset]. Zenodo. https://doi.org/10.5281/zenodo.4686358</li> </ol> Source code in <code>src/redplanet/Mag/depth/loader.py</code> <pre><code>@substitute_docstrings\ndef get_dataset(\n    as_dict: bool = False,\n    _extras: bool = False,\n) -&gt; pd.DataFrame | list[dict]:\n    \"\"\"\n    Get the full magnetic source depth dataset.\n\n    Data (0.038 MiB) is provided by {@Gong2021_data.n}. The full paper discusses/analyzes the models in detail ({@Gong2021_paper.p}).\n\n\n    Parameters\n    ----------\n    as_dict : bool, optional\n        If True, return the data as a list of dictionaries. Default is False.\n    _extras : bool, optional\n        Please ignore this, it is used for internal purposes only.\n\n\n    Returns\n    -------\n    pd.DataFrame | list[dict]\n        Information about all 412 dipoles. Columns are:\n\n        - `lon` : float\n            - Longitude in range [-180, 180].\n        - `lat` : float\n            - Latitude in range [-90, 90].\n        - `chi_reduced` : float\n            - \"reduced chi^2 value of the best fitting model\"\n        - `cap_radius_km` : list[float]\n            - \"angular radii of the magnetized caps (best-fit, and 1-sigma lower/upper limits)\"\n        - `depth_km` : list[float]\n            - \"magnetization depth (best-fit, and 1-sigma lower/upper limits)\"\n        - `dipole_mment_Am2` : list[float]\n            - \"square root of the metric N&lt;M^2&gt;V^2 [in A m^2] (best-fit, and 1-sigma lower/upper limits)\"\n\n        Note that the 1-sigma lower/upper values are NaN when the minimum reduced chi^2 value of the best fitting model is outside the 1-sigma confidence level of the reduced chi^2 that were obtained from Monte Carlo simulations.\n    \"\"\"\n    if _dat_depths is None:\n        _load()\n    if as_dict:\n        return _dat_depths.to_dict(orient='records')\n    if _extras:\n        return (_dat_depths, _dat_nearest_dipole)\n    return _dat_depths\n</code></pre>"},{"location":"usage/datasets/Mag/depth/get_grid/","title":"get_grid(...)","text":""},{"location":"usage/datasets/Mag/depth/get_grid/#redplanet.Mag.depth.get_grid","title":"redplanet.Mag.depth.get_grid","text":"<pre><code>get_grid(\n    lon: float | numpy.ndarray,\n    lat: float | numpy.ndarray,\n    col: str,\n) -&gt; ndarray\n</code></pre> <p>Similar to <code>get_nearest</code>, but significantly more optimized for accessing data over large areas by using a pre-computed grid of nearest dipole locations.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>float | np.ndarray</code> <p>Longitude coordinate(s) in range [-180, 360].</p> required <code>lat</code> <code>float | np.ndarray</code> <p>Latitude coordinate(s) in range [-90, 90].</p> required <code>col</code> <code>str</code> <p>Name of dataset column to return. See <code>redplanet.Mag.depth.get_dataset</code> for options/explanations.</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>Data values at the input coordinates, with shape <code>(num_lats, num_lons)</code>. For columns with three values (e.g. <code>'depth_km'</code>), the shape will be <code>(3, num_lats, num_lons)</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the specified column is not found in the dataset.</p> Source code in <code>src/redplanet/Mag/depth/getter.py</code> <pre><code>@substitute_docstrings\ndef get_grid(\n    lon : float | np.ndarray,\n    lat : float | np.ndarray,\n    col : str,\n) -&gt; np.ndarray:\n    \"\"\"\n    Similar to `get_nearest`, but significantly more optimized for accessing data over large areas by using a pre-computed grid of nearest dipole locations.\n\n    Parameters\n    ----------\n    {param.lon}\n    {param.lat}\n    col : str\n        Name of dataset column to return. See `redplanet.Mag.depth.get_dataset` for options/explanations.\n\n    Returns\n    -------\n    np.ndarray\n        Data values at the input coordinates, with shape `(num_lats, num_lons)`. For columns with three values (e.g. `'depth_km'`), the shape will be `(3, num_lats, num_lons)`.\n\n    Raises\n    ------\n    ValueError\n        If the specified column is not found in the dataset.\n    \"\"\"\n\n    df_depths, dat_nearest_dipole = get_dataset(_extras=True)\n\n    if col not in df_depths.columns:\n        raise ValueError(f\"Column '{col}' not found in dataset. Available columns are: {df_depths.columns.tolist()}\")\n\n    col_values = np.stack(df_depths[col])\n    dat_idx = dat_nearest_dipole.get_values(lon, lat, 'dat')\n\n    dat_return = col_values[dat_idx]\n\n    if dat_return.ndim == 3:\n        dat_return = np.moveaxis(dat_return, 2, 0)\n\n    return dat_return\n</code></pre>"},{"location":"usage/datasets/Mag/depth/get_nearest/","title":"get_nearest(...)","text":""},{"location":"usage/datasets/Mag/depth/get_nearest/#redplanet.Mag.depth.get_nearest","title":"redplanet.Mag.depth.get_nearest","text":"<pre><code>get_nearest(\n    lon: float, lat: float, as_dict: bool = False\n) -&gt; pandas.core.frame.DataFrame | list[dict]\n</code></pre> <p>Get magnetic source depth data, sorted from closest to furthest from the given point.</p> <p>For source of the dataset, see references of <code>help(redplanet.Mag.depth.get_nearest)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>float</code> <p>Longitude coordinate in range [-180, 360].</p> required <code>lat</code> <code>float</code> <p>Latitude coordinate in range [-90, 90].</p> required <code>as_dict</code> <code>bool</code> <p>If True, return the data as a list of dictionaries. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>pd.DataFrame | list[dict]</code> <p>Information about all 412 dipoles, sorted from closest to furthest from the given input coordinate. Columns are identical to those in <code>redplanet.Mag.depth.get_dataset</code> (look there for full explanations), with the addition of a computed column:</p> <ul> <li><code>distance_km</code> : float<ul> <li>Distance from the given input coordinate to the dipole, in km.</li> </ul> </li> </ul> Source code in <code>src/redplanet/Mag/depth/getter.py</code> <pre><code>def get_nearest(\n    lon     : float,\n    lat     : float,\n    as_dict : bool = False,\n) -&gt; pd.DataFrame | list[dict]:\n    \"\"\"\n    Get magnetic source depth data, sorted from closest to furthest from the given point.\n\n    For source of the dataset, see references of `help(redplanet.Mag.depth.get_nearest)`.\n\n    Parameters\n    ----------\n    lon : float\n        Longitude coordinate in range [-180, 360].\n    lat : float\n        Latitude coordinate in range [-90, 90].\n    as_dict : bool, optional\n        If True, return the data as a list of dictionaries. Default is False.\n\n    Returns\n    -------\n    pd.DataFrame | list[dict]\n        Information about all 412 dipoles, sorted from closest to furthest from the given input coordinate. Columns are identical to those in `redplanet.Mag.depth.get_dataset` (look there for full explanations), with the addition of a computed column:\n\n        - `distance_km` : float\n            - Distance from the given input coordinate to the dipole, in km.\n    \"\"\"\n\n    lon = _plon2slon(lon)\n\n    df_depths = get_dataset().copy()\n\n    distances_km = geodesy.get_distance(\n        start = np.array([lon, lat]),\n        end   = df_depths[['lon', 'lat']].to_numpy(),\n    )[:,0] / 1.e3\n\n    df_depths['distance_km'] = distances_km\n    df_depths.sort_values('distance_km', inplace=True)\n\n    if as_dict:\n        df_depths = df_depths.to_dict(orient='records')\n\n    return df_depths\n</code></pre>"},{"location":"usage/datasets/Mag/sh/get/","title":"get(...)","text":""},{"location":"usage/datasets/Mag/sh/get/#redplanet.Mag.sh.get","title":"redplanet.Mag.sh.get","text":"<pre><code>get(\n    lon: float | numpy.ndarray,\n    lat: float | numpy.ndarray,\n    quantity: str = \"total\",\n    as_xarray: bool = False,\n) -&gt; (\n    float | numpy.ndarray | xarray.core.dataarray.DataArray\n)\n</code></pre> <p>Get magnetic field values at the specified coordinates. Dataset must be loaded first, see <code>redplanet.Mag.sh.load(...)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>float | np.ndarray</code> <p>Longitude coordinate(s) in range [-180, 360].</p> required <code>lat</code> <code>float | np.ndarray</code> <p>Latitude coordinate(s) in range [-90, 90].</p> required <code>quantity</code> <code>str</code> <p>Options are: ['radial', 'theta', 'phi', 'total', 'potential'], by default 'total'.</p> <code>'total'</code> <code>as_xarray</code> <code>bool</code> <p>If True, return the data as an <code>xarray.DataArray</code>. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>float | np.ndarray | xr.DataArray</code> <p>Data values at the the input coordinates. The return type is determined as follows:</p> <ul> <li>float: if both <code>lon</code> and <code>lat</code> are floats.</li> <li>numpy.ndarray (1D): if one of <code>lon</code> or <code>lat</code> is a numpy 1D array and the other is a float.</li> <li>numpy.ndarray (2D): if both <code>lon</code> and <code>lat</code> are numpy 1D arrays. The first dimension of output array corresponds to <code>lat</code> values.</li> <li>xarray.DataArray: see <code>as_xarray</code> parameter (this takes precedence over the above types).</li> </ul> <p>Units are nanotesla [nT].</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>quantity</code> is not one of ['radial', 'theta', 'phi', 'total', 'potential.</p> Source code in <code>src/redplanet/Mag/sh/getter.py</code> <pre><code>@substitute_docstrings\ndef get(\n    lon       : float | np.ndarray,\n    lat       : float | np.ndarray,\n    quantity  : str  = 'total',\n    as_xarray : bool = False\n) -&gt; float | np.ndarray | xr.DataArray:\n    \"\"\"\n    Get magnetic field values at the specified coordinates. Dataset must be loaded first, see `redplanet.Mag.sh.load(...)`.\n\n    Parameters\n    ----------\n    {param.lon}\n    {param.lat}\n    quantity : str, optional\n        Options are: ['radial', 'theta', 'phi', 'total', 'potential'], by default 'total'.\n    {param.as_xarray}\n\n    Returns\n    -------\n    {return.GriddedData}\n\n        Units are nanotesla [nT].\n\n    Raises\n    ------\n    ValueError\n        If `quantity` is not one of ['radial', 'theta', 'phi', 'total', 'potential.\n    \"\"\"\n\n    q = ['radial', 'theta', 'phi', 'total', 'potential']\n    if quantity not in q:\n        raise ValueError(f\"Quantity {quantity} is not in list of supported quantities: {q}.\")\n\n    dat_mag = get_dataset()\n\n    return dat_mag.get_values(\n        lon = lon,\n        lat = lat,\n        var = quantity,\n        as_xarray = as_xarray,\n    )\n</code></pre>"},{"location":"usage/datasets/Mag/sh/get_dataset/","title":"get_dataset()","text":""},{"location":"usage/datasets/Mag/sh/get_dataset/#redplanet.Mag.sh.get_dataset","title":"redplanet.Mag.sh.get_dataset","text":"<pre><code>get_dataset() -&gt; GriddedData\n</code></pre> <p>Get the underlying dataset which is currently loaded.</p> <p>Returns:</p> Type Description <code>GriddedData</code> <p>Instance of RedPlanet's <code>GriddedData</code> class, which stores all coordinate/data/metadata information and accessing/plotting methods.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset has not been loaded yet (see the <code>load</code> function for this module).</p> See Also <p><code>redplanet.helper_functions.GriddedData</code></p> Source code in <code>src/redplanet/Mag/sh/loader.py</code> <pre><code>@substitute_docstrings\ndef get_dataset() -&gt; GriddedData:\n    \"\"\"\n    {fulldoc.get_dataset_GriddedData}\n    \"\"\"\n    if _dat_mag is None:\n        raise ValueError('Bouguer dataset not loaded. Use `redplanet.Mag.sh.load(&lt;model_params&gt;)`.')\n    return _dat_mag\n</code></pre>"},{"location":"usage/datasets/Mag/sh/get_metadata/","title":"get_metadata()","text":""},{"location":"usage/datasets/Mag/sh/get_metadata/#redplanet.Mag.sh.get_metadata","title":"redplanet.Mag.sh.get_metadata","text":"<pre><code>get_metadata() -&gt; dict\n</code></pre> <p>Get metadata for the dataset which is currently loaded.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Contains information about the dataset such as description, units, references, download links, local file path, etc.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset has not been loaded yet (see the <code>load</code> function for this module).</p> Source code in <code>src/redplanet/Mag/sh/loader.py</code> <pre><code>@substitute_docstrings\ndef get_metadata() -&gt; dict:\n    \"\"\"\n    {fulldoc.get_metadata}\n    \"\"\"\n    return dict(get_dataset().metadata)\n</code></pre>"},{"location":"usage/datasets/Mag/sh/load/","title":"load(...)","text":""},{"location":"usage/datasets/Mag/sh/load/#redplanet.Mag.sh.load","title":"redplanet.Mag.sh.load","text":"<pre><code>load(model: str = None, lmax: int = 134) -&gt; None\n</code></pre> <p>Load a magnetic field model for Mars.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Name of the magnetic field model to load. Options are:</p> <ul> <li><code>'Langlais2019'</code> (0.081 MiB) \u2014 Spherical harmonic model of the magnetic field of Mars with a spatial resolution of ~160 km at the surface, corresponding to spherical harmonic degree 134. Integrates data from MGS magnetometer, MGS electron reflectometer, and MAVEN magnetometer.<ul> <li>Dataset downloaded from Langlais (2019). The full paper discusses/analyzes the models in detail (Langlais et al., 2019).</li> <li>We process spherical harmonic coefficients with <code>pyshtools</code> (Wieczorek et al., 2024; Wieczorek &amp; Meschede, 2018).</li> </ul> </li> </ul> <code>None</code> <code>lmax</code> <code>int</code> <p>The maximum spherical harmonic degree of the coefficients to load. Default is 134 (maximum for 'Langlais2019').</p> <code>134</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid model name is provided.</p> References <ol> <li>Langlais, B. (2019). Spherical harmonic model of the magnetic field of Mars to degree 134 [Dataset]. Zenodo. https://doi.org/10.5281/zenodo.3876714</li> <li>Langlais, B., Th\u00e9bault, E., Houliez, A., Purucker, M. E., &amp; Lillis, R. J. (2019). A New Model of the Crustal Magnetic Field of Mars Using MGS and MAVEN. Journal of Geophysical Research: Planets, 124(6), 1542-1569. https://doi.org/10.1029/2018JE005854</li> <li>Wieczorek, M. A., &amp; Meschede, M. (2018). SHTools: Tools for Working with Spherical Harmonics. Geochemistry, Geophysics, Geosystems, 19(8), 2574-2592. https://doi.org/10.1029/2018GC007529</li> <li>Wieczorek, M. A., Meschede, M., Broquet, A., Brugere, T., Corbin, A., EricAtORS, Hattori, A., Kalinin, A., Kohler, J., Kutra, D., Leinweber, K., Lobo, P., Maia, J., Mentzer, E., Minton, D., Oshchepkov, I., Phan, P. L., Poplawski, O., Reinecke, M., Sales de Andrade, E., Schnetter, E., Schr\u00f6der, S., Shin, D., Sierra, J., Vasishta, A., Walker, A., xoviat, &amp; Xu, B. (2024). SHTOOLS/SHTOOLS: Version 4.13.1. Zenodo. https://doi.org/10.5281/zenodo.12698962</li> </ol> Source code in <code>src/redplanet/Mag/sh/loader.py</code> <pre><code>@substitute_docstrings\ndef load(\n    model : str = None,\n    lmax  : int = 134,\n) -&gt; None:\n    \"\"\"\n    Load a magnetic field model for Mars.\n\n    Parameters\n    ----------\n    model : str\n        Name of the magnetic field model to load. Options are:\n\n        - `'Langlais2019'` (0.081 MiB) \u2014 Spherical harmonic model of the magnetic field of Mars with a spatial resolution of ~160 km at the surface, corresponding to spherical harmonic degree 134. Integrates data from MGS magnetometer, MGS electron reflectometer, and MAVEN magnetometer.\n            - Dataset downloaded from {@Langlais2019_data.n}. The full paper discusses/analyzes the models in detail ({@Langlais2019_paper.p}).\n            - We process spherical harmonic coefficients with `pyshtools` ({@shtools_code.p}; {@shtools_paper.p}).\n    lmax : int, optional\n        The maximum spherical harmonic degree of the coefficients to load. Default is 134 (maximum for 'Langlais2019').\n\n    Raises\n    ------\n    ValueError\n        If an invalid model name is provided.\n    \"\"\"\n\n    ## I expect to add more later, so users should explicitly choose Genova2016 for forward compatibility. Mittelholz might be publishing hers soon.\n    info = {\n        'Langlais2019': {\n            'metadata': {\n                'description': 'Martian magnetic field model, based on 14386 ESD, inversion using MGS MAG, MGS ER and MAVEN MAG, field predicted at 150km altitude. SH model, ref surface =3393.5 km, from Langlais/Thebault/Houliez/Purucker/Lillis internal coefficients.',\n                'units'      : 'nT',\n                'lmax'       : lmax,\n                'links'      : {\n                    'data' : 'https://doi.org/10.5281/zenodo.3876714',\n                    'paper': 'https://doi.org/10.1029/2018JE005854',\n                },\n            },\n        },\n    }\n\n    if model not in info:\n        raise ValueError(f\"Invalid magnetic field model: '{model}'. Options are: {list(info.keys())}.\")\n\n\n\n    if model == 'Langlais2019':\n\n        fpath = _get_fpath_dataset(model)\n\n        '''\n        - Arguments for `from_file` are taken directly from the `pyshtools` source code (`pyshools.datasets.Mars.Langlais2019()`).\n            - I rewrite it so the dataset is downloaded to `redplanet` cache rather than `pyshtools` cache, ensuring `redplanet` can fully manage/clear its own dataset cache.\n        '''\n        ds = (\n            pysh.shclasses.SHMagCoeffs.from_file(\n                fpath,\n                lmax       = lmax,\n                skip       = 4,\n                r0         = 3393.5e3,\n                header     = False,\n                file_units = 'nT',\n                units      = 'nT',\n                encoding   = 'utf-8',\n            )\n            .expand()\n            .to_xarray()\n            .isel(lat=slice(None, None, -1))  ## in pysh, lats are always decreasing at first\n        )\n\n\n        data_dict = {}\n        for data_var in list(ds.data_vars):\n            data_dict[data_var] = ds[data_var].values\n\n        metadata = info[model]['metadata']\n        metadata['fpath'] = fpath\n\n\n        global _dat_mag\n        _dat_mag = GriddedData(\n            lon       = ds.lon.values,\n            lat       = ds.lat.values,\n            is_slon   = False,\n            data_dict = data_dict,\n            metadata  = metadata,\n        )\n\n\n\n    else:\n        raise ValueError(f\"THE DEVELOPER MESSED UP. THIS SHOULD NOT HAPPEN.\")\n\n    return\n</code></pre>"},{"location":"usage/helper_functions/plot/","title":"plot(...)","text":""},{"location":"usage/helper_functions/plot/#redplanet.plot","title":"redplanet.plot","text":"<pre><code>plot(\n    lons: ndarray,\n    lats: ndarray,\n    dat: ndarray,\n    ax: None | matplotlib.axes._axes.Axes = None,\n    figsize: float | tuple[float, float] = (7, 7),\n    xlabel: str = \"Longitude\",\n    ylabel: str = \"Latitude\",\n    title: None | str = None,\n    cmap: str = \"RdBu_r\",\n    cbar: bool = True,\n    cbar_label: None | str = None,\n    cbar_units: None | str | tuple[str, float] = None,\n    limits: tuple[None | float, None | float] = [\n        None,\n        None,\n    ],\n    hillshade: bool = False,\n    topo_model: str = \"DEM_463m\",\n    azimuth: int = 0,\n    altitude: int = 70,\n    alpha_hs: float = 1,\n    alpha_dat: float = 0.6,\n    show: bool = True,\n) -&gt; tuple[\n    matplotlib.figure.Figure, matplotlib.axes._axes.Axes\n]\n</code></pre> <p>Plots a 2D dataset with optional hillshade underlay.</p> <p>Parameters:</p> Name Type Description Default <code>lons</code> <code>np.ndarray</code> <p>1D array of longitudes, likely the ones used to create the data array.</p> required <code>lats</code> <code>np.ndarray</code> <p>1D array of latitudes, likely the ones used to create the data array.</p> required <code>dat</code> <code>np.ndarray</code> <p>2D array of data values to be visualized. Shape should be <code>(len(lats), len(lons))</code>.</p> required <code>ax</code> <code>None | plt.Axes</code> <p>Existing Matplotlib Axes object on which to plot the data, e.g. if you're using subplots to put multiple plots on the same figure. If None, a new figure and axes are created. Default is None.</p> <code>None</code> <code>figsize</code> <code>float | tuple[float, float]</code> <p>Width, height of the figure in inches. If a single number is provided, it is used for both width and height. Default is (7, 7).</p> <code>(7, 7)</code> <code>xlabel</code> <code>str</code> <p>Label for the x-axis. Default is 'Longitude'.</p> <code>'Longitude'</code> <code>ylabel</code> <code>str</code> <p>Label for the y-axis. Default is 'Latitude'.</p> <code>'Latitude'</code> <code>title</code> <code>None | str</code> <p>Title of the plot. If None, no title is set. Default is None.</p> <code>None</code> <code>cmap</code> <code>str</code> <p>Colormap used to display the data. Default is 'RdBu_r'.</p> <code>'RdBu_r'</code> <code>cbar</code> <code>None | bool</code> <p>Whether to display a colorbar alongside the plot. Default is True.</p> <code>True</code> <code>cbar_label</code> <code>None | str</code> <p>Label for the colorbar. Default is None.</p> <code>None</code> <code>cbar_units</code> <code>str | tuple[str, float]</code> <p>Units to display on the colorbar. If a tuple is provided, it should be in the form <code>(unit_name, scale)</code> where the data is scaled by the given factor before plotting. Default is None.</p> <code>None</code> <code>limits</code> <code>tuple[None | float, None | float]</code> <p>Tuple specifying the (minimum, maximum) limits for the data colormap scaling. If you only want to set one limit, use None for the other. Default is [None, None].</p> <code>[None, None]</code> <code>hillshade</code> <code>bool</code> <p>If True, underlays a hillshade generated from topographic data. Default is False.</p> <code>False</code> <code>topo_model</code> <code>str</code> <p>(For hillshade) Identifier for the topographic model used to generate the hillshade. See <code>Crust.topo.load(...)</code> for options. Default is 'DEM_463m'.</p> <code>'DEM_463m'</code> <code>azimuth</code> <code>int</code> <p>(For hillshade) Azimuth angle (in degrees) representing the horizontal direction of the light source (measured clockwise from north). Default is 0.</p> <code>0</code> <code>altitude</code> <code>int</code> <p>(For hillshade) Altitude angle (in degrees) representing the vertical angle of the light source above the horizon. Default is 70.</p> <code>70</code> <code>alpha_hs</code> <code>float</code> <p>(For hillshade) Opacity for the hillshade underlay (range 0 to 1). Default is 1.</p> <code>1</code> <code>alpha_dat</code> <code>float</code> <p>(For hillshade) Opacity for the data overlay (range 0 to 1). If hillshade is disabled, this is set to 1. Default is 0.6.</p> <code>0.6</code> <code>show</code> <code>bool</code> <p>If True and a new figure is created (i.e. <code>ax</code> is not provided), displays the plot immediately. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>tuple[plt.Figure, plt.Axes]</code> <p>A tuple containing the matplotlib Figure and Axes objects for the created plot.</p> Source code in <code>src/redplanet/helper_functions/plotter.py</code> <pre><code>def plot(\n    lons       : np.ndarray,\n    lats       : np.ndarray,\n    dat        : np.ndarray,\n    ax         : None | plt.Axes = None,\n    figsize    : float | tuple[float, float] = (7, 7),\n    xlabel     : str = 'Longitude',\n    ylabel     : str = 'Latitude',\n    title      : None | str = None,\n    cmap       : str = 'RdBu_r',\n    cbar       : bool = True,\n    cbar_label : None | str = None,\n    cbar_units : None | str | tuple[str, float ] = None,\n    limits     : tuple[ None|float, None|float ] = [None, None],\n    hillshade  : bool = False,\n    topo_model : str = 'DEM_463m',\n    azimuth    : int = 0,\n    altitude   : int = 70,\n    alpha_hs   : float = 1,\n    alpha_dat  : float = 0.6,\n    show       : bool = True,\n) -&gt; tuple[plt.Figure, plt.Axes]:\n    \"\"\"\n    Plots a 2D dataset with optional hillshade underlay.\n\n    Parameters\n    ----------\n    lons : np.ndarray\n        1D array of longitudes, likely the ones used to create the data array.\n    lats : np.ndarray\n        1D array of latitudes, likely the ones used to create the data array.\n    dat : np.ndarray\n        2D array of data values to be visualized. Shape should be `(len(lats), len(lons))`.\n    ax : None | plt.Axes, optional\n        Existing Matplotlib Axes object on which to plot the data, e.g. if you're using subplots to put multiple plots on the same figure. If None, a new figure and axes are created. Default is None.\n    figsize : float | tuple[float, float], optional\n        Width, height of the figure in inches. If a single number is provided, it is used for both width and height. Default is (7, 7).\n    xlabel : str, optional\n        Label for the x-axis. Default is 'Longitude'.\n    ylabel : str, optional\n        Label for the y-axis. Default is 'Latitude'.\n    title : None | str, optional\n        Title of the plot. If None, no title is set. Default is None.\n    cmap : str, optional\n        Colormap used to display the data. Default is 'RdBu_r'.\n    cbar : None | bool, optional\n        Whether to display a colorbar alongside the plot. Default is True.\n    cbar_label : None | str, optional\n        Label for the colorbar. Default is None.\n    cbar_units : str | tuple[str, float ], optional\n        Units to display on the colorbar. If a tuple is provided, it should be in the form `(unit_name, scale)` where the data is scaled by the given factor before plotting. Default is None.\n    limits : tuple[ None|float, None|float ], optional\n        Tuple specifying the (minimum, maximum) limits for the data colormap scaling. If you only want to set one limit, use None for the other. Default is [None, None].\n    hillshade : bool, optional\n        If True, underlays a hillshade generated from topographic data. Default is False.\n    topo_model : str, optional\n        (For hillshade) Identifier for the topographic model used to generate the hillshade. See `Crust.topo.load(...)` for options. Default is 'DEM_463m'.\n    azimuth : int, optional\n        (For hillshade) Azimuth angle (in degrees) representing the horizontal direction of the light source (measured clockwise from north). Default is 0.\n    altitude : int, optional\n        (For hillshade) Altitude angle (in degrees) representing the vertical angle of the light source above the horizon. Default is 70.\n    alpha_hs : float, optional\n        (For hillshade) Opacity for the hillshade underlay (range 0 to 1). Default is 1.\n    alpha_dat : float, optional\n        (For hillshade) Opacity for the data overlay (range 0 to 1). If hillshade is disabled, this is set to 1. Default is 0.6.\n    show : bool, optional\n        If True and a new figure is created (i.e. `ax` is not provided), displays the plot immediately. Default is True.\n\n    Returns\n    -------\n    tuple[plt.Figure, plt.Axes]\n        A tuple containing the matplotlib Figure and Axes objects for the created plot.\n    \"\"\"\n\n    if isinstance(figsize, int | float):\n        figsize = (figsize, figsize)\n\n\n    # If no axis is provided, create a new figure and axis.\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n        created_new_fig = True\n    else:\n        fig = ax.figure\n        created_new_fig = False\n\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n\n    if title:\n        ax.set_title(title)\n\n\n    '''compute hillshade &amp; plot hillshade if necessary'''\n\n    if hillshade:\n\n        ## temporarily offshore the user's topo model (in order to load the requested model for hillshade), then restore it later on \u2014 plotting something shouldn't change external state (the user's topo model), that's horrible and anti-user design !!!\n        user_topo = Crust.topo.loader._dat_topo\n\n        if (user_topo is None) or (user_topo.metadata['short_name'] != topo_model):\n            Crust.topo.load(topo_model)\n\n        ## account for the fact that input data arrays might be super low-res (e.g. GRS), but we still want high-res hillshade\n        hs_lons = np.linspace(lons[0], lons[-1], 1000)\n        hs_lats = np.linspace(lats[0], lats[-1], 1000)\n\n        dat_hs = topo_to_hillshade(\n            topography       = Crust.topo.get(hs_lons, hs_lats),\n            meters_per_pixel = Crust.topo.get_metadata()['meters_per_pixel'],\n            azimuth          = azimuth,\n            altitude         = altitude,\n        )\n\n        Crust.topo.loader._dat_topo = user_topo\n\n        im_hs = ax.imshow(\n            dat_hs,\n            cmap = 'Greys_r',\n            origin = 'lower',\n            aspect = 'equal',\n            extent = [hs_lons[0], hs_lons[-1], hs_lats[0], hs_lats[-1]],\n            alpha = alpha_hs,\n        )\n\n    else:\n        alpha_dat = 1\n\n\n    '''plot data'''\n\n    if isinstance(cbar_units, (tuple, list)):\n        cbar_units_name, scale = cbar_units\n        dat = dat * scale\n    else:\n        cbar_units_name = cbar_units\n\n    im_dat = ax.imshow(\n        dat,\n        cmap = cmap,\n        origin = 'lower',\n        aspect = 'equal',\n        extent = [lons[0], lons[-1], lats[0], lats[-1]],\n        alpha = alpha_dat,\n        vmin = limits[0],\n        vmax = limits[1],\n    )\n\n\n    '''plot colorbar'''\n\n    if cbar:\n        divider = make_axes_locatable(ax)\n        cax = divider.append_axes(\"right\", size=\"3%\", pad=0.2)  ## `size` sets colorbar width to X% of main axes; `pad` sets separation between axes and colorbar to X inches\n        cbar = fig.colorbar(im_dat, cax=cax)\n        label = ''\n        if cbar_label:\n            label += cbar_label\n        if cbar_units_name:\n            label += f' [{cbar_units_name}]'\n        cbar.set_label(label)\n\n    if show and created_new_fig:\n        plt.show()\n\n    return fig, ax\n</code></pre>"},{"location":"usage/helper_functions/coordinates/_plon2slon/","title":"_plon2slon(...)","text":""},{"location":"usage/helper_functions/coordinates/_plon2slon/#redplanet.helper_functions.coordinates._plon2slon","title":"redplanet.helper_functions.coordinates._plon2slon","text":"<pre><code>_plon2slon(\n    plon: float | list | numpy.ndarray,\n) -&gt; float | list | numpy.ndarray\n</code></pre> <p>Convert positive longitudes (in range [0, 360]) to signed longitudes (in range [-180, 180]). Inputs in range [-180, 0] are returned as is.</p> <p>Parameters:</p> Name Type Description Default <code>plon</code> <code>float | list | np.ndarray</code> <p>Longitude value(s) in positive format.</p> required <p>Returns:</p> Type Description <code>float | list | np.ndarray</code> <p>Converted longitude value(s) in signed format. The return type matches the input type.</p> Notes <p>Actual mapping over the full input range:</p> <ul> <li>[-180, 180) --&gt; [-180, 180)</li> <li>[180, 360]  --&gt; [-180, 0]</li> </ul> <p>Self reminder:</p> <ul> <li>Signed longitude   [-180, 180]  --&gt;  Arabia Terra in middle &amp; Hellas on right.</li> <li>Positive longitude [0, 360]     --&gt;  Olympus Mons in middle &amp; Hellas on left.</li> </ul> Source code in <code>src/redplanet/helper_functions/coordinates.py</code> <pre><code>def _plon2slon(\n    plon: float | list | np.ndarray\n) -&gt; float | list | np.ndarray:\n    \"\"\"\n    Convert positive longitudes (in range [0, 360]) to signed longitudes (in range [-180, 180]). Inputs in range [-180, 0] are returned as is.\n\n    Parameters\n    ----------\n    plon : float | list | np.ndarray\n        Longitude value(s) in positive format.\n\n    Returns\n    -------\n    float | list | np.ndarray\n        Converted longitude value(s) in signed format. The return type matches the input type.\n\n    Notes\n    -----\n    Actual mapping over the full input range:\n\n    - [-180, 180) --&gt; [-180, 180)\n    - [180, 360]  --&gt; [-180, 0]\n\n    Self reminder:\n\n    - Signed longitude   [-180, 180]  --&gt;  Arabia Terra in middle &amp; Hellas on right.\n    - Positive longitude [0, 360]     --&gt;  Olympus Mons in middle &amp; Hellas on left.\n    \"\"\"\n    def convert(plon):\n        return ((plon - 180) % 360) - 180\n\n    if isinstance(plon, (float, np.ndarray)):\n        return convert(plon)\n    else:\n        return convert(np.array(plon)).tolist()\n</code></pre>"},{"location":"usage/helper_functions/coordinates/_slon2plon/","title":"_slon2plon(...)","text":""},{"location":"usage/helper_functions/coordinates/_slon2plon/#redplanet.helper_functions.coordinates._slon2plon","title":"redplanet.helper_functions.coordinates._slon2plon","text":"<pre><code>_slon2plon(\n    slon: float | list | numpy.ndarray,\n) -&gt; float | list | numpy.ndarray\n</code></pre> <p>Convert signed longitudes (in range [-180, 180]) to positive longitudes (in range [0, 360]). Inputs in range [180, 360] are returned as is.</p> <p>Parameters:</p> Name Type Description Default <code>slon</code> <code>float | list | np.ndarray</code> <p>Longitude value(s) in signed format.</p> required <p>Returns:</p> Type Description <code>float | list | np.ndarray</code> <p>Converted longitude value(s) in positive format. The return type matches the input type.</p> See Also <p>_plon2slon : Converts positive longitudes to signed longitudes.</p> Source code in <code>src/redplanet/helper_functions/coordinates.py</code> <pre><code>def _slon2plon(\n    slon: float | list | np.ndarray\n) -&gt; float | list | np.ndarray:\n    \"\"\"\n    Convert signed longitudes (in range [-180, 180]) to positive longitudes (in range [0, 360]). Inputs in range [180, 360] are returned as is.\n\n    Parameters\n    ----------\n    slon : float | list | np.ndarray\n        Longitude value(s) in signed format.\n\n    Returns\n    -------\n    float | list | np.ndarray\n        Converted longitude value(s) in positive format. The return type matches the input type.\n\n    See Also\n    --------\n    _plon2slon : Converts positive longitudes to signed longitudes.\n    \"\"\"\n    def convert(slon):\n        return slon % 360\n\n    if isinstance(slon, (float, np.ndarray)):\n        return convert(slon)\n    else:\n        return convert(np.array(slon)).tolist()\n</code></pre>"},{"location":"usage/helper_functions/geodesy/get_distance/","title":"get_distance(...)","text":""},{"location":"usage/helper_functions/geodesy/get_distance/#redplanet.helper_functions.geodesy.get_distance","title":"redplanet.helper_functions.geodesy.get_distance","text":"<pre><code>get_distance(\n    start: list | numpy.ndarray, end: list | numpy.ndarray\n) -&gt; ndarray\n</code></pre> <p>Calculate the geodesic distance between two points on the surface of Mars.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>list | np.ndarray</code> <p>Array of shape (2) or (n_points, 2) containing the longitude and latitude coordinates of the starting point(s).</p> required <code>end</code> <code>list | np.ndarray</code> <p>Similar to <code>start</code>, but for the ending point(s).</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>Array of shape (n_points) [? verify this] containing the geodesic distances between the corresponding starting and ending point(s).</p> See Also <p>cartopy.geodesic.Geodesic.circle</p> Notes <p>Details on the Mars reference ellipsoid (oblate ellipsoid) used for these calculations:</p> <ul> <li>Parameters:<ul> <li>Semimajor axis   : 3395428 m</li> <li>Flattening       : 0.005227617843759314</li> <li>GM               : 42828372000000.0 m\u00b3/s\u00b2</li> <li>Angular velocity : 7.0882181e-05 rad/s</li> </ul> </li> <li>Sources:<ul> <li>Main:<ul> <li>Ardalan, A. A., Karimi, R., &amp; Grafarend, E. W. (2009). A New Reference Equipotential Surface, and Reference Ellipsoid for the Planet Mars. Earth, Moon, and Planets, 106, 1-13.</li> <li>https://doi.org/10.1007/s11038-009-9342-7</li> </ul> </li> <li>(Found it here:)<ul> <li>https://www.fatiando.org/boule/latest/ellipsoids.html</li> </ul> </li> </ul> </li> </ul> <p>For geodesic calculations, we use cartopy.geodesic.Geodesic.circle.</p> Source code in <code>src/redplanet/helper_functions/geodesy.py</code> <pre><code>def get_distance(\n    start : list | np.ndarray,\n    end   : list | np.ndarray,\n) -&gt; np.ndarray:\n    \"\"\"\n    Calculate the geodesic distance between two points on the surface of Mars.\n\n    Parameters\n    ----------\n    start : list | np.ndarray\n        Array of shape (2) or (n_points, 2) containing the longitude and latitude coordinates of the starting point(s).\n    end : list | np.ndarray\n        Similar to `start`, but for the ending point(s).\n\n    Returns\n    -------\n    np.ndarray\n        Array of shape (n_points) [? verify this] containing the geodesic distances between the corresponding starting and ending point(s).\n\n    See Also\n    --------\n    [cartopy.geodesic.Geodesic.circle](https://scitools.org.uk/cartopy/docs/latest/reference/generated/cartopy.geodesic.Geodesic.html)\n\n    Notes\n    -----\n    Details on the Mars reference ellipsoid (oblate ellipsoid) used for these calculations:\n\n    - Parameters:\n        - Semimajor axis   : 3395428 m\n        - Flattening       : 0.005227617843759314\n        - GM               : 42828372000000.0 m\u00b3/s\u00b2\n        - Angular velocity : 7.0882181e-05 rad/s\n    - Sources:\n        - Main:\n            - Ardalan, A. A., Karimi, R., &amp; Grafarend, E. W. (2009). A New Reference Equipotential Surface, and Reference Ellipsoid for the Planet Mars. Earth, Moon, and Planets, 106, 1-13.\n            - https://doi.org/10.1007/s11038-009-9342-7\n        - (Found it here:)\n            - https://www.fatiando.org/boule/latest/ellipsoids.html\n\n    For geodesic calculations, we use [cartopy.geodesic.Geodesic.circle](https://scitools.org.uk/cartopy/docs/latest/reference/generated/cartopy.geodesic.Geodesic.html).\n    \"\"\"\n    geodesic = __get_mars_geodesic()\n    return geodesic.inverse(start, end)\n</code></pre>"},{"location":"usage/helper_functions/geodesy/make_circle/","title":"make_circle(...)","text":""},{"location":"usage/helper_functions/geodesy/make_circle/#redplanet.helper_functions.geodesy.make_circle","title":"redplanet.helper_functions.geodesy.make_circle","text":"<pre><code>make_circle(\n    lon: float,\n    lat: float,\n    radius: float,\n    n_samples: int = 180,\n    endpoint: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Generate a geodesic circle of points on the surface of Mars.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>float</code> <p>Longitude coordinate of the center of the circle, in range [-180, 360].</p> required <code>lat</code> <code>float</code> <p>Latitude coordinate of the center of the circle, in range [-90, 90].</p> required <code>radius</code> <code>float</code> <p>Radius of the circle in meters.</p> required <code>endpoint</code> <code>bool</code> <p>If True, include the starting point at the end of the circle. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>np.ndarray</code> <p>Array of shape (n_samples, 2) [? verify this] containing the longitude and latitude coordinates of the circle points.</p> See Also <p>For more details about the reference ellipsoid, see <code>redplanet.helper_functions.geodesy.get_distance</code>.</p> Source code in <code>src/redplanet/helper_functions/geodesy.py</code> <pre><code>def make_circle(\n    lon       : float,\n    lat       : float,\n    radius    : float,  ## TODO: should this be suffixed with '_m' or '_km' to indicate units...?\n    n_samples : int  = 180,\n    endpoint  : bool = False,\n) -&gt; np.ndarray:\n    \"\"\"\n    Generate a geodesic circle of points on the surface of Mars.\n\n    Parameters\n    ----------\n    lon : float\n        Longitude coordinate of the center of the circle, in range [-180, 360].\n    lat : float\n        Latitude coordinate of the center of the circle, in range [-90, 90].\n    radius : float\n        Radius of the circle in meters.\n    endpoint : bool, optional\n        If True, include the starting point at the end of the circle. Default is False.\n\n    Returns\n    -------\n    np.ndarray\n        Array of shape (n_samples, 2) [? verify this] containing the longitude and latitude coordinates of the circle points.\n\n    See Also\n    --------\n    For more details about the reference ellipsoid, see `redplanet.helper_functions.geodesy.get_distance`.\n    \"\"\"\n    geodesic = __get_mars_geodesic()\n    return geodesic.circle(lon, lat, radius, n_samples, endpoint)\n</code></pre>"},{"location":"usage/helper_functions/geodesy/move_forward/","title":"move_forward(...)","text":""},{"location":"usage/helper_functions/geodesy/move_forward/#redplanet.helper_functions.geodesy.move_forward","title":"redplanet.helper_functions.geodesy.move_forward","text":"<pre><code>move_forward(\n    start: list | numpy.ndarray,\n    azimuth: float | list | numpy.ndarray,\n    distance: float,\n) -&gt; ndarray\n</code></pre> <p>Calculate the coordinates of a point on the surface of Mars after moving a certain geodesic distance along a given angle.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>list | np.ndarray</code> <p>Array of shape (2) containing the longitude and latitude coordinates of the starting point.</p> required <code>azimuth</code> <code>float | list | np.ndarray</code> <p>Array of shape (n_points) containing the azimuth angle(s) to \"move forward\" in degrees, where 0 is north and 90 is east.</p> required <code>distance</code> <code>float</code> <p>The geodesic distance to move forward in meters.</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>Array of shape (2) or (n_points, 2) [? verify this] containing the longitude and latitude coordinates of the point(s) after moving forward.</p> See Also <p>For more details about the reference ellipsoid and geodesic calculations, see <code>redplanet.helper_functions.geodesy.get_distance</code>.</p> Source code in <code>src/redplanet/helper_functions/geodesy.py</code> <pre><code>def move_forward(\n    start    : list | np.ndarray,\n    azimuth  : float | list | np.ndarray,\n    distance : float,\n) -&gt; np.ndarray:\n    \"\"\"\n    Calculate the coordinates of a point on the surface of Mars after moving a certain geodesic distance along a given angle.\n\n    Parameters\n    ----------\n    start : list | np.ndarray\n        Array of shape (2) containing the longitude and latitude coordinates of the starting point.\n    azimuth : float | list | np.ndarray\n        Array of shape (n_points) containing the azimuth angle(s) to \"move forward\" in degrees, where 0 is north and 90 is east.\n    distance : float\n        The geodesic distance to move forward in meters.\n\n    Returns\n    -------\n    np.ndarray\n        Array of shape (2) or (n_points, 2) [? verify this] containing the longitude and latitude coordinates of the point(s) after moving forward.\n\n    See Also\n    --------\n    For more details about the reference ellipsoid and geodesic calculations, see `redplanet.helper_functions.geodesy.get_distance`.\n    \"\"\"\n    geodesic = __get_mars_geodesic()\n    return geodesic.direct(start, azimuth, distance)[:,:2]\n</code></pre>"},{"location":"usage/helper_functions/misc/prefetch/","title":"prefetch()","text":""},{"location":"usage/helper_functions/misc/prefetch/#redplanet.DatasetManager.prefetch","title":"redplanet.DatasetManager.prefetch","text":"<pre><code>prefetch() -&gt; None\n</code></pre> <p>Download a few key datasets to cache. This is primarily meant for the demo notebook.</p> Source code in <code>src/redplanet/DatasetManager/prefetcher.py</code> <pre><code>def prefetch() -&gt; None:\n    \"\"\"\n    Download a few key datasets to cache. This is primarily meant for the demo notebook.\n    \"\"\"\n\n    print(f'Cache directory: {user_config.get_dirpath_datacache()}')\n\n    ## declare which datasets to download (these correspond to keys in `redplanet.DatasetManager.dataset_info._DATASETS`)\n    names = [\n        'GRS_v2',\n        'dichotomy_coords',\n        'moho_registry',\n        'crater_db',\n        'Langlais2019',\n        'Genova2016',\n        'MOLA_shape_719',\n        'Gong &amp; Weiczorek, 2021',\n        'magdepth_nearest_dipoles',\n        # 'DEM_200m',\n        'DEM_463m',\n        # 'SH_5km',\n        # 'SH_10km',\n    ]\n\n    # ## DEBUG: delete all if they exist\n    # for name in names:\n    #     fpath = _get_fpath_dataset(name)\n    #     if fpath.exists():\n    #         fpath.unlink()\n\n    ## calculate size of all datasets (not accounting for what's already downloaded)\n    sum_size_mib = 0\n    for name in names:\n        sum_size_mib += _DATASETS[name]['size_mib']\n    print(f'(Total download size: {sum_size_mib:.2f} MiB)')\n    print()\n\n    # ## download all (superseded by progress bar)\n    # for name in names:\n    #     print(f'Downloading: \"{name}\" ({_DATASETS[name][\"size_mib\"]:0.2f} MiB)')\n    #     fpath = _get_fpath_dataset(name)\n\n    ## download all, with progress bar\n    with tqdm(total=len(names), desc=\"Downloading datasets\") as pbar:\n        for name in names:\n            pbar.set_postfix(current=f'\"{name}\" ({_DATASETS[name][\"size_mib\"]:0.2f} MiB)')\n            _get_fpath_dataset(name)\n            pbar.update(1)\n</code></pre>"},{"location":"usage/helper_functions/misc/timer/","title":"timer(...)","text":""},{"location":"usage/helper_functions/misc/timer/#redplanet.helper_functions.misc.timer","title":"redplanet.helper_functions.misc.timer","text":"<pre><code>timer(message='', d=3)\n</code></pre> <p>A context manager that measures the time taken to execute the code block within it.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>A message to display when the code block is executed, by default nothing.</p> <code>''</code> <code>d</code> <code>int</code> <p>The number of decimal places to display in the elapsed time, by default 3.</p> <code>3</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from redplanet.helper_functions.misc import timer\n&gt;&gt;&gt; with timer('Elapsed time: '):\n...     print(f'Sum of first 10^7 squared integers: {sum(x*x for x in range(10_000_000)):,}')\n</code></pre> <p>Sum of first 10^7 squared integers: 333,333,283,333,335,000,000 Elapsed time: 0.886 seconds</p> Source code in <code>src/redplanet/helper_functions/misc.py</code> <pre><code>@contextmanager\ndef timer(message='', d=3):\n    \"\"\"\n    A context manager that measures the time taken to execute the code block within it.\n\n    Parameters\n    ----------\n    message : str, optional\n        A message to display when the code block is executed, by default nothing.\n    d : int, optional\n        The number of decimal places to display in the elapsed time, by default 3.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from redplanet.helper_functions.misc import timer\n    &gt;&gt;&gt; with timer('Elapsed time: '):\n    ...     print(f'Sum of first 10^7 squared integers: {sum(x*x for x in range(10_000_000)):,}')\n\n    Sum of first 10^7 squared integers: 333,333,283,333,335,000,000\n    Elapsed time: 0.886 seconds\n    \"\"\"\n    start = time.time()\n    yield\n    end = time.time()\n    elapsed = end - start\n    print(f\"{message}{elapsed:.{d}f} seconds\")\n</code></pre>"},{"location":"usage/user_config/get_dirpath_datacache/","title":"get_dirpath_datacache()","text":""},{"location":"usage/user_config/get_dirpath_datacache/#redplanet.user_config.get_dirpath_datacache","title":"redplanet.user_config.get_dirpath_datacache","text":"<pre><code>get_dirpath_datacache() -&gt; Path\n</code></pre> <p>Get the data path where datasets are downloaded/cached. Initializes to default path ('/home//.cache/redplanet/') if not set. <p>Returns:</p> Type Description <code>Path</code> Notes <p>[DEVELOPER NOTES:]</p> <ul> <li>It's good design to defer initialization of default value until first access in <code>get_dirpath_datacache()</code>...<ul> <li>This way, we avoid any overhead or side-effects of executing any potentially expensive / unnecessary code (esp related to file system operations) during the module import (i.e. lazy initialization).</li> </ul> </li> </ul> Source code in <code>src/redplanet/user_config/datacache.py</code> <pre><code>def get_dirpath_datacache() -&gt; Path:\n    \"\"\"\n    Get the data path where datasets are downloaded/cached. Initializes to default path ('/home/&lt;user&gt;/.cache/redplanet/') if not set.\n\n    Returns\n    -------\n    Path\n\n    Notes\n    -----\n    [DEVELOPER NOTES:]\n\n    - It's good design to defer initialization of default value until first access in `get_dirpath_datacache()`...\n        - This way, we avoid any overhead or side-effects of executing any potentially expensive / unnecessary code (esp related to file system operations) during the module import (i.e. lazy initialization).\n    \"\"\"\n    ## Lazy load\n    if _dirpath_datacache is None:\n        set_dirpath_datacache(\n            Path(user_cache_dir(appname='redplanet')).resolve()\n        )\n    return _dirpath_datacache\n</code></pre>"},{"location":"usage/user_config/get_enable_stream_hash_check/","title":"get_enable_stream_hash_check()","text":""},{"location":"usage/user_config/get_enable_stream_hash_check/#redplanet.user_config.get_enable_stream_hash_check","title":"redplanet.user_config.get_enable_stream_hash_check","text":"<pre><code>get_enable_stream_hash_check() -&gt; bool\n</code></pre> <p>Get the current value of the flag that determines whether we verify the hash of a file at URL by streaming before fully downloading it.</p> <p>Returns:</p> Type Description <code>bool</code> Source code in <code>src/redplanet/user_config/stream_hash_check.py</code> <pre><code>def get_enable_stream_hash_check() -&gt; bool:\n    \"\"\"\n    Get the current value of the flag that determines whether we verify the hash of a file at URL by streaming before fully downloading it.\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return _enable_stream_hash_check\n</code></pre>"},{"location":"usage/user_config/get_max_size_to_calculate_hash_GiB/","title":"get_max_size_to_calculate_hash_GiB()","text":""},{"location":"usage/user_config/get_max_size_to_calculate_hash_GiB/#redplanet.user_config.get_max_size_to_calculate_hash_GiB","title":"redplanet.user_config.get_max_size_to_calculate_hash_GiB","text":"<pre><code>get_max_size_to_calculate_hash_GiB() -&gt; float | None\n</code></pre> <p>Get the maximum size of a local file (in GiB) for which a hash will be calculated in order to verify its integrity. If the file is larger than this size, the hash will not be calculated.</p> <p>Returns:</p> Type Description <code>float | None</code> Notes <p>IMPLEMENTATION NOTE: if this returns <code>None</code>, then all hashes are calculated by default (to see implementation logic, check <code>redplanet.DatasetManager.main._get_fpath_dataset()</code>).</p> Source code in <code>src/redplanet/user_config/max_hash_size.py</code> <pre><code>def get_max_size_to_calculate_hash_GiB() -&gt; float | None:\n    \"\"\"\n    Get the maximum size of a local file (in GiB) for which a hash will be calculated in order to verify its integrity. If the file is larger than this size, the hash will not be calculated.\n\n    Returns\n    -------\n    float | None\n\n    Notes\n    -----\n    IMPLEMENTATION NOTE: if this returns `None`, then all hashes are calculated by default (to see implementation logic, check `redplanet.DatasetManager.main._get_fpath_dataset()`).\n    \"\"\"\n    return _max_size_to_calculate_hash_GiB\n</code></pre>"},{"location":"usage/user_config/set_dirpath_datacache/","title":"set_dirpath_datacache(...)","text":""},{"location":"usage/user_config/set_dirpath_datacache/#redplanet.user_config.set_dirpath_datacache","title":"redplanet.user_config.set_dirpath_datacache","text":"<pre><code>set_dirpath_datacache(\n    target_path: str | pathlib.Path,\n) -&gt; None\n</code></pre> <p>Set the data path where datasets will be downloaded/cached.</p> <p>Parameters:</p> Name Type Description Default <code>target_path</code> <code>str | Path</code> <p>The file system path to store datasets.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>Path must be a string or a Path object.</p> <code>ValueError</code> <p>Invalid path string provided.</p> Source code in <code>src/redplanet/user_config/datacache.py</code> <pre><code>def set_dirpath_datacache(target_path: str | Path) -&gt; None:\n    \"\"\"\n    Set the data path where datasets will be downloaded/cached.\n\n    Parameters\n    ----------\n    target_path : str | Path\n        The file system path to store datasets.\n\n    Raises\n    ------\n    TypeError\n        Path must be a string or a Path object.\n    ValueError\n        Invalid path string provided.\n    \"\"\"\n    ## Input type validation &amp;&amp; conversion to Path object\n    match target_path:\n\n        case Path():\n            target_path = target_path.resolve()\n\n        case str():\n            try:\n                target_path = Path(target_path).resolve()\n            except Exception as e:\n                raise ValueError(f'Invalid path string provided: {target_path}\\n{e}')\n\n        case _:\n            raise TypeError('Path must be a string or a Path object.')\n\n    ## Proceed\n    global _dirpath_datacache\n    _dirpath_datacache = target_path\n    return\n</code></pre>"},{"location":"usage/user_config/set_enable_stream_hash_check/","title":"set_enable_stream_hash_check(...)","text":""},{"location":"usage/user_config/set_enable_stream_hash_check/#redplanet.user_config.set_enable_stream_hash_check","title":"redplanet.user_config.set_enable_stream_hash_check","text":"<pre><code>set_enable_stream_hash_check(value: bool) -&gt; None\n</code></pre> <p>Set the flag that determines whether we verify the hash of a file at URL by streaming before fully downloading it.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bool</code> required Source code in <code>src/redplanet/user_config/stream_hash_check.py</code> <pre><code>def set_enable_stream_hash_check(value: bool) -&gt; None:\n    \"\"\"\n    Set the flag that determines whether we verify the hash of a file at URL by streaming before fully downloading it.\n\n    Parameters\n    ----------\n    value : bool\n    \"\"\"\n    global _enable_stream_hash_check\n    _enable_stream_hash_check = value\n    return\n</code></pre>"},{"location":"usage/user_config/set_max_size_to_calculate_hash_GiB/","title":"set_max_size_to_calculate_hash_GiB(...)","text":""},{"location":"usage/user_config/set_max_size_to_calculate_hash_GiB/#redplanet.user_config.set_max_size_to_calculate_hash_GiB","title":"redplanet.user_config.set_max_size_to_calculate_hash_GiB","text":"<pre><code>set_max_size_to_calculate_hash_GiB(value: float) -&gt; None\n</code></pre> <p>Set the maximum size of a local file (in GiB) for which a hash will be calculated in order to verify its integrity. If the file is larger than this size, the hash will not be calculated.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> required Source code in <code>src/redplanet/user_config/max_hash_size.py</code> <pre><code>def set_max_size_to_calculate_hash_GiB(value: float) -&gt; None:\n    \"\"\"\n    Set the maximum size of a local file (in GiB) for which a hash will be calculated in order to verify its integrity. If the file is larger than this size, the hash will not be calculated.\n\n    Parameters\n    ----------\n    value : float\n    \"\"\"\n    global _max_size_to_calculate_hash_GiB\n    _max_size_to_calculate_hash_GiB = value\n    return\n</code></pre>"}]}